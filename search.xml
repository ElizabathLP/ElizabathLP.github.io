<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>HBase 集群安装</title>
      <link href="/posts/34ad406f/"/>
      <url>/posts/34ad406f/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="Hbase-安装"><a href="#Hbase-安装" class="headerlink" title="Hbase 安装"></a>Hbase 安装</h1><p>以三台机器搭建集群环境为例</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hbase1 10.10.3.129</span><br><span class="line"></span><br><span class="line">hbase2 10.10.3.130</span><br><span class="line"></span><br><span class="line">hbase3 10.10.3.131</span><br></pre></td></tr></table></figure><h2 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h2><h3 id="创建相关用户"><a href="#创建相关用户" class="headerlink" title="创建相关用户"></a>创建相关用户</h3><blockquote><p>三台机器操作方式相同</p></blockquote><p>创建zookeeper、Hbase、Hadoop用户,并设置密码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# useradd zookeeper</span><br><span class="line">[root@localhost opt]# passwd zookeeper</span><br><span class="line">[root@localhost opt]# useradd hadoop</span><br><span class="line">[root@localhost opt]# passwd hadoop</span><br><span class="line">[root@localhost opt]# useradd hbase</span><br><span class="line">[root@localhost opt]# passwd hbase</span><br></pre></td></tr></table></figure><p>将此三个用户加入到 sudoers 中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# vim /etc/sudoers</span><br></pre></td></tr></table></figure><h3 id="Hosts-与-免密"><a href="#Hosts-与-免密" class="headerlink" title="Hosts 与 免密"></a>Hosts 与 免密</h3><blockquote><p>三台机器操作方式相同</p></blockquote><p>编辑hosts</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# vim &#x2F;etc&#x2F;hosts</span><br></pre></td></tr></table></figure><p>在文件末尾增加以下内容</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hbase1 10.10.3.129</span><br><span class="line">hbase2 10.10.3.130</span><br><span class="line">hbase3 10.10.3.131</span><br></pre></td></tr></table></figure><p>编辑hostname</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# vim /etc/sysconfig/network</span><br></pre></td></tr></table></figure><p>填入以下内容(根据相应IP对应关系，在相应hosts上配置)</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">HOSTNAME</span>=<span class="string">hbase1</span></span><br></pre></td></tr></table></figure><p>免密</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# ssh-keygen</span><br><span class="line">Generating public/private rsa key pair.</span><br><span class="line">Enter file in which to save the key (/root/.ssh/id_rsa): </span><br><span class="line">Enter passphrase (empty for no passphrase): </span><br><span class="line">Enter same passphrase again: </span><br><span class="line">Your identification has been saved in /root/.ssh/id_rsa.</span><br><span class="line">Your public key has been saved in /root/.ssh/id_rsa.pub.</span><br><span class="line">The key fingerprint is:</span><br><span class="line">SHA256:F142fovQQib0Kgl/WL/USKPv8z/8Xfb0O5/dD/wA+Fo root@localhost.localdomain</span><br><span class="line">The key's randomart image is:</span><br><span class="line">+---[RSA 2048]----+</span><br><span class="line">|        .        |</span><br><span class="line">|       . .       |</span><br><span class="line">|    .   o B +    |</span><br><span class="line">|     o + X @ .   |</span><br><span class="line">|      = S X = .  |</span><br><span class="line">|       o + = = . |</span><br><span class="line">|          o E.= +|</span><br><span class="line">|         ..o  oBO|</span><br><span class="line">|          oo...=/|</span><br><span class="line">+----[SHA256]-----+</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# ssh-copy-id hbase1</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"</span><br><span class="line">The authenticity of host 'hbase1 (10.10.3.129)' can't be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:GkgGCNlxc55obBDytcgmvK5kJXR5wHuhKejQwr/yxfg.</span><br><span class="line">ECDSA key fingerprint is MD5:1f:70:01:4a:06:a8:66:e7:88:47:bf:4c:0f:30:5b:52.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line">root@hbase1's password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   "ssh 'hbase1'"</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# ssh-copy-id hbase2</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"</span><br><span class="line">The authenticity of host 'hbase2 (10.10.3.130)' can't be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:GkgGCNlxc55obBDytcgmvK5kJXR5wHuhKejQwr/yxfg.</span><br><span class="line">ECDSA key fingerprint is MD5:1f:70:01:4a:06:a8:66:e7:88:47:bf:4c:0f:30:5b:52.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line">root@hbase2's password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   "ssh 'hbase2'"</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br><span class="line"></span><br><span class="line">[root@localhost ~]# ssh-copy-id hbase3</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"</span><br><span class="line">The authenticity of host 'hbase3 (10.10.3.131)' can't be established.</span><br><span class="line">ECDSA key fingerprint is SHA256:GkgGCNlxc55obBDytcgmvK5kJXR5wHuhKejQwr/yxfg.</span><br><span class="line">ECDSA key fingerprint is MD5:1f:70:01:4a:06:a8:66:e7:88:47:bf:4c:0f:30:5b:52.</span><br><span class="line">Are you sure you want to continue connecting (yes/no)? yes</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed</span><br><span class="line">/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys</span><br><span class="line">root@hbase3's password: </span><br><span class="line"></span><br><span class="line">Number of key(s) added: 1</span><br><span class="line"></span><br><span class="line">Now try logging into the machine, with:   "ssh 'hbase3'"</span><br><span class="line">and check to make sure that only the key(s) you wanted were added.</span><br></pre></td></tr></table></figure><p>分别切换到hadoop用户，执行上方免密操作，方式相同</p><h3 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h3><blockquote><p>三台机器操作方式相同</p></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# systemctl stop firewalld</span><br><span class="line">[root@localhost ~]# systemctl disable firewalld</span><br></pre></td></tr></table></figure><h3 id="JDK-1-8"><a href="#JDK-1-8" class="headerlink" title="JDK 1.8"></a>JDK 1.8</h3><blockquote><p>三台机器操作方式相同</p></blockquote><p>下载 JDK1.8 安装包</p><p>放置到 <code>/opt</code> 下并解压</p><p>重命名文件夹为 <code>jdk</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# tar -zxvf jdk-8u251-linux-x64.tar.gz</span><br><span class="line">[root@localhost opt]# mv /opt/jdk1.8.0_251 /opt/jdk</span><br></pre></td></tr></table></figure><p>配置环境变量</p><p>编辑 <code>/etc/profile</code></p><p>在文件末尾增加两行</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> jdk 相关</span></span><br><span class="line">export JAVA_HOME=/opt/jdk</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br></pre></td></tr></table></figure><p>加载新配置的环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# source /etc/profile</span><br></pre></td></tr></table></figure><h3 id="重启机器"><a href="#重启机器" class="headerlink" title="重启机器"></a>重启机器</h3><blockquote><p>三台机器操作方式相同</p></blockquote><h2 id="安装-Zookeeper"><a href="#安装-Zookeeper" class="headerlink" title="安装 Zookeeper"></a>安装 Zookeeper</h2><blockquote><p>三台机器操作方式相同</p></blockquote><p>下载 Zookeeper 安装包</p><p>放置到 <code>/opt</code> 下并解压</p><p>重命名文件夹为 <code>zookeeper</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# tar -zxvf apache-zookeeper-3.5.7-bin.tar.gz</span><br><span class="line">[root@localhost opt]# mv /opt/apache-zookeeper-3.5.7-bin /opt/zookeeper</span><br></pre></td></tr></table></figure><p>配置环境变量</p><p>编辑 <code>/etc/profile</code></p><p>在文件末尾增加</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> zookeeper相关</span></span><br><span class="line">export ZOOKEEPER_HOME=/opt/zookeeper</span><br></pre></td></tr></table></figure><p>加载新配置的环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# source /etc/profile</span><br></pre></td></tr></table></figure><p>创建数据存放路径，日志存放路径，创建zookeeper ID文件，并赋权。其中 <code>your id</code>为你的zookeeper节点ID，需保证三台不重复，且为数字</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# mkdir -p /data/zookeeper</span><br><span class="line">[root@localhost opt]# mkdir -p /var/log/zookeeper</span><br><span class="line">[root@localhost opt]# echo "your id" &gt; /data/zookeeper/myid</span><br><span class="line">[root@localhost opt]# chown -R zookeeper:zookeeper /data/zookeeper</span><br><span class="line">[root@localhost opt]# chown -R zookeeper:zookeeper /var/log/zookeeper</span><br><span class="line">[root@localhost opt]# chown -R zookeeper:zookeeper /opt/zookeeper</span><br></pre></td></tr></table></figure><p>创建 zookeeper 配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# cp $ZOOKEEPER_HOME/conf/zoo_sample.cfg $ZOOKEEPER_HOME/conf/zoo.cfg</span><br></pre></td></tr></table></figure><p>编辑 zookeeper 配置文件，修改 <code>dataDir</code> 参数</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">dataDir</span>=<span class="string">/data/zookeeper</span></span><br></pre></td></tr></table></figure><p>编辑 zookeeper 配置文件，增加以下参数(server.id 为你上方的 zookeeper 节点ID)</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">server.1</span>=<span class="string">hbase1:2888:3888</span></span><br><span class="line"><span class="meta">server.2</span>=<span class="string">hbase2:2888:3888</span></span><br><span class="line"><span class="meta">server.3</span>=<span class="string">hbase3:2888:3888</span></span><br></pre></td></tr></table></figure><h2 id="安装-Hadoop"><a href="#安装-Hadoop" class="headerlink" title="安装 Hadoop"></a>安装 Hadoop</h2><blockquote><p>此操作三台相同，三台是相同的配置文件</p></blockquote><p>下载 Hadoop 安装包</p><p>放置到 <code>/opt</code> 下并解压</p><p>重命名文件夹为 <code>hadoop</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# tar -zxvf hadoop-2.8.1.tar.gz</span><br><span class="line">[root@localhost opt]# mv /opt/hadoop-2.8.1 /opt/hadoop</span><br></pre></td></tr></table></figure><p>配置环境变量</p><p>编辑 <code>/etc/profile</code></p><p>在文件末尾增加</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> hadoop 相关</span></span><br><span class="line">export HADOOP_HOME=/opt/hadoop</span><br><span class="line">export HADOOP_PREFIX=$HADOOP_HOME</span><br><span class="line">export HADOOP_MAPRED_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_HDFS_HOME=$HADOOP_HOME</span><br><span class="line">export YARN_HOME=$HADOOP_HOME</span><br><span class="line">export HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/native</span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin</span><br><span class="line">export HADOOP_INSTALL=$HADOOP_HOME</span><br></pre></td></tr></table></figure><p>加载新配置的环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# source /etc/profile</span><br></pre></td></tr></table></figure><h4 id="编辑-Hadoop-相关配置文件"><a href="#编辑-Hadoop-相关配置文件" class="headerlink" title="编辑 Hadoop 相关配置文件"></a>编辑 Hadoop 相关配置文件</h4><h5 id="slaves"><a href="#slaves" class="headerlink" title="slaves"></a>slaves</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# vim $HADOOP_HOME/etc/hadoop/slaves</span><br></pre></td></tr></table></figure><p>填入 ip 与hosts的映射关系</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hbase1 10.10.3.129</span><br><span class="line">hbase2 10.10.3.130</span><br><span class="line">hbase3 10.10.3.131</span><br></pre></td></tr></table></figure><h5 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# vim $HADOOP_HOME/etc/hadoop/hdfs-site.xml</span><br></pre></td></tr></table></figure><p>完整配置文件如下</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hbase1,hbase2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.hbase1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hbase1:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.hbase1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hbase1:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.mycluster.hbase2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hbase2:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.mycluster.hbase2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hbase2:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://hbase1:8485;hbase2:8485;hbase3:8485/mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.mycluster<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hadoop/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/hadoop/hdfs/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///data/hadoop/hdfs/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/hadoop/hdfs/journalnode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.qjournal.start-segment.timeout.ms<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>60000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hbase1:2181,hbase2:2181,hbase3:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h5 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a>core-site.xml</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# vim $HADOOP_HOME/etc/hadoop/core-site.xml</span><br></pre></td></tr></table></figure><p>完整配置文件如下</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type="text/xsl" href="configuration.xsl"?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the "License");</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an "AS IS" BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://mycluster<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.session-timeout.ms<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>30000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h5 id="hadoop-env-sh"><a href="#hadoop-env-sh" class="headerlink" title="hadoop-env.sh"></a>hadoop-env.sh</h5><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# vim $HADOOP_HOME/etc/hadoop/hadoop-env.sh</span><br></pre></td></tr></table></figure><p>在文件头部填入以下内容</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_NAMENODE_OPTS=" -Xms1024m -Xmx1024m -XX:+UseParallelGC"</span><br><span class="line">export HADOOP_DATANODE_OPTS=" -Xms1024m -Xmx1024m"</span><br><span class="line">export HADOOP_LOG_DIR=/var/log/hadoop</span><br></pre></td></tr></table></figure><h4 id="创建相关文件夹"><a href="#创建相关文件夹" class="headerlink" title="创建相关文件夹"></a>创建相关文件夹</h4><p>创建数据存放路径，日志存放路径，并赋权。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# mkdir -p /data/hadoop/hdfs</span><br><span class="line">[root@localhost opt]# mkdir -p /data/hadoop/hdfs/journalnode</span><br><span class="line">[root@localhost opt]# mkdir -p /var/log/hadoop</span><br><span class="line">[root@localhost opt]# chown -R hadoop:hadoop /data/hadoop</span><br><span class="line">[root@localhost opt]# chown -R hadoop:hadoop /var/log/hadoop</span><br><span class="line">[root@localhost opt]# chown -R hadoop:hadoop /opt/hadoop</span><br></pre></td></tr></table></figure><h2 id="安装HBase"><a href="#安装HBase" class="headerlink" title="安装HBase"></a>安装HBase</h2><blockquote><p>此操作三台相同，三台是相同的配置文件</p></blockquote><p>下载 HBase安装包</p><p>放置到 <code>/opt</code> 下并解压</p><p>重命名文件夹为 <code>hbase</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# tar -zxvf hbase-2.3.0-bin.tar.gz</span><br><span class="line">[root@localhost opt]# mv /opt/hbase-2.3.0 /opt/hbase</span><br></pre></td></tr></table></figure><p>配置环境变量</p><p>编辑 <code>/etc/profile</code></p><p>在文件末尾增加</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> hbase相关</span></span><br><span class="line">export HBASE_HOME=/opt/hbase</span><br><span class="line">export PATH=$PATH:$HBASE_HOME/bin</span><br></pre></td></tr></table></figure><p>加载新配置的环境变量</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# source /etc/profile</span><br></pre></td></tr></table></figure><h4 id="编辑相关配置文件"><a href="#编辑相关配置文件" class="headerlink" title="编辑相关配置文件"></a>编辑相关配置文件</h4><h5 id="hdfs-site-xml-1"><a href="#hdfs-site-xml-1" class="headerlink" title="hdfs-site.xml"></a>hdfs-site.xml</h5><p>将hadoop下的hdfs-xite.xml 复制或软链接一份到  <code>$HBASE_HOME/conf</code> 下。这里建议软连接</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# ln -s /opt/hadoop/etc/hadoop/hdfs-site.xml /opt/hbase/conf/hdfs-site.xml</span><br></pre></td></tr></table></figure><h5 id="hbase-site-xml"><a href="#hbase-site-xml" class="headerlink" title="hbase-site.xml"></a>hbase-site.xml</h5><p>在原文件中增加如下内容</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.rootdir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://mycluster/hbase<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.property.dataDir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>/data/hbase/zookeeper<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.cluster.distributed<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>hbase129,hbase130,hbase131<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h5 id="hbase-env-sh"><a href="#hbase-env-sh" class="headerlink" title="hbase-env.sh"></a>hbase-env.sh</h5><p>修改配置文件中 <code>HBASE_CLASSPATH</code> 内容，如有注释，请先取消注释</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export HBASE_CLASSPATH=/opt/hadoop/etc/hadoop</span><br><span class="line">export HBASE_LOG_DIR=/var/log/hbase</span><br><span class="line">export HBASE_MANAGES_ZK=false</span><br></pre></td></tr></table></figure><h4 id="创建相关文件夹-1"><a href="#创建相关文件夹-1" class="headerlink" title="创建相关文件夹"></a>创建相关文件夹</h4><p>创建数据存放路径，日志存放路径，并赋权。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost opt]# mkdir -p /data/hbase</span><br><span class="line">[root@localhost opt]# mkdir -p /data/hbase/zookeeper</span><br><span class="line">[root@localhost opt]# mkdir -p /var/log/hbase</span><br><span class="line">[root@localhost opt]# chown -R hbase:hbase /data/hbase</span><br><span class="line">[root@localhost opt]# chown -R hbase:hbase /var/log/hbase</span><br><span class="line">[root@localhost opt]# chown -R hbase:hbase /opt/hbase</span><br></pre></td></tr></table></figure><h2 id="初始化-Zookeeper"><a href="#初始化-Zookeeper" class="headerlink" title="初始化 Zookeeper"></a>初始化 Zookeeper</h2><blockquote><p>此操作三台相同</p><p>启动前请注意关闭防火墙</p></blockquote><p>切换到 zookeeper 用户</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# su - zookeeper</span><br></pre></td></tr></table></figure><p>启动 Zookeeper 服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[zookeeper@localhost ~]# $ZOOKEEPER_HOME/bin/zkServer.sh start</span><br></pre></td></tr></table></figure><p>然后查看Zookeeper集群状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[zookeeper@localhost ~]# $ZOOKEEPER_HOME/bin/zkServer.sh status</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/zookeeper/bin/../conf/zoo.cfg</span><br><span class="line">Client port found: 2181. Client address: localhost.</span><br><span class="line">Mode: leader</span><br></pre></td></tr></table></figure><p>查看返回信息，如果集群中显示有两个 <code>follower</code> 和一个 <code>leader</code> ，说明集群启动成功</p><h2 id="初始化HDFS"><a href="#初始化HDFS" class="headerlink" title="初始化HDFS"></a>初始化HDFS</h2><blockquote><p>三台机器操作相同</p></blockquote><p>切换到 hadoop 用户</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# su - hadoop</span><br></pre></td></tr></table></figure><h3 id="1-启动-journalnode-服务"><a href="#1-启动-journalnode-服务" class="headerlink" title="1. 启动 journalnode 服务"></a>1. 启动 journalnode 服务</h3><blockquote><p>三台机器操作相同</p></blockquote><p>启动 journalnode 服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh start journalnode</span><br></pre></td></tr></table></figure><p>然后查看相关进程信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost ~]# jps</span><br><span class="line">2410 Jps</span><br><span class="line">15231 JournalNode</span><br></pre></td></tr></table></figure><p>查看返回信息，如果显示了 <code>JournalNode</code> 进程，且查看日志没有发现相关错误信息，说明 <code>JournalNode</code> 启动成功</p><p>查看 <code>JournalNode</code>  日志信息(后边的 <code>hbase1</code> 是你的主机名称，其他两台根据实际情况更换主机名即可)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@localhost ~]# /var/log/hadoop/hadoop-hadoop-journalnode-hbase1.log</span><br></pre></td></tr></table></figure><h3 id="2-初始化-Namenode"><a href="#2-初始化-Namenode" class="headerlink" title="2. 初始化 Namenode"></a>2. 初始化 Namenode</h3><p>在第一台机器上，也就是 <code>hbase1</code> 上，执行以下代码进行初始化</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 初始化主namenode</span></span><br><span class="line">[hadoop@hbase1 ~]# hdfs namenode -format</span><br></pre></td></tr></table></figure><p>如果没有相关错误信息，且初始化成功结束，说明主 <code>namenode</code> 初始化成功</p><p>然后启动刚初始化的 <code>namenode</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start namenode</span><br></pre></td></tr></table></figure><p>在第二台机器上，也就是 <code>hbase2</code> 上，执行以下代码进行初始化</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 初始化备namenode</span></span><br><span class="line">[hadoop@hbase2 ~]# hdfs namenode -bootstrapStandby</span><br></pre></td></tr></table></figure><p>接下来关闭第一台刚启动的 <code>namenode</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs stop namenode</span><br></pre></td></tr></table></figure><p>然后初始化 <code>JournalNode</code>  中的记录，在第一台 <code>namenode</code> 上执行以下命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]# hdfs namenode -initializeSharedEdits</span><br></pre></td></tr></table></figure><p>启动刚初始化好的两台 <code>namenode</code>  </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1(hbase2) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start namenode</span><br></pre></td></tr></table></figure><p>然后在两台<code>namenode</code>分别查看相关进程信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]$ jps</span><br><span class="line">15792 NameNode</span><br><span class="line">2648 Jps</span><br><span class="line">15231 JournalNode</span><br></pre></td></tr></table></figure><p>查看返回信息，如果显示了 <code>namenode</code>  进程，且查看日志没有发现相关错误信息，说明 <code>namenode</code>  启动成功</p><p>查看 <code>namenode</code>  日志信息(后边的 <code>hbase1</code> 是你的主机名称，其他两台根据实际情况更换主机名即可)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]# /var/log/hadoop/hadoop-hadoop-namenode-hbase1.log</span><br></pre></td></tr></table></figure><h3 id="3-初始化-zkfc"><a href="#3-初始化-zkfc" class="headerlink" title="3. 初始化 zkfc"></a>3. 初始化 zkfc</h3><p>在第一台机器上，也就是 <code>hbase1</code> 上，执行以下代码进行初始化</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 初始化zkfc</span></span><br><span class="line">[hadoop@hbase1 ~]# hdfs zkfc -formatZK</span><br></pre></td></tr></table></figure><p>如果没有相关错误信息，且初始化成功结束，查看 <code>zookeeper</code> 中相关信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看zookeeper中相关信息</span></span><br><span class="line">[hadoop@hbase1 ~]# $ZOOKEEPER_HOME/bin/zkCli.sh</span><br><span class="line">Connecting to localhost:2181</span><br><span class="line">[zk: localhost:2181(CONNECTED) 0] ls /</span><br><span class="line">[hadoop-ha, zookeeper]</span><br></pre></td></tr></table></figure><p>可以看到多出了一个 <code>hadoop-ha</code> 目录，说明初始化正确</p><p>接下来停止两台 <code>namenode</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1(hbase2) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs stop namenode</span><br></pre></td></tr></table></figure><p>然后启动两台 <code>namenode</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1(hbase2) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start namenode</span><br></pre></td></tr></table></figure><p>通过浏览器访问 <code>&lt;hostname&gt;:50070</code> 可以看到两台 <code>namenode</code> 现在都处于 <code>standby</code> 状态</p><p>两台启动 <code>zkfc</code> </p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1(hbase2) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start zkfc</span><br></pre></td></tr></table></figure><p>然后在两台<code>namenode</code>分别查看相关进程信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]$ jps</span><br><span class="line">15792 NameNode</span><br><span class="line">15908 DFSZKFailoverController</span><br><span class="line">5339 Jps</span><br><span class="line">15231 JournalNode</span><br></pre></td></tr></table></figure><p>查看返回信息，如果显示了 <code>DFSZKFailoverController</code>  进程，且查看日志没有发现相关错误信息，说明 <code>zkfc</code> 启动成功</p><p>查看 <code>namenode</code>  日志信息(后边的 <code>hbase1</code> 是你的主机名称，其他两台根据实际情况更换主机名即可)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]# /var/log/hadoop/hadoop-hadoop-namenode-hbase1.log</span><br></pre></td></tr></table></figure><p>通过浏览器访问 <code>&lt;hostname&gt;:50070</code> 可以看到两台 <code>namenode</code> 其中一台处于 <code>active</code> 状态，另一台处于 <code>standby</code> 状态，说明 <code>zkfc</code>  初始化工作完成</p><h3 id="4-启动-DataNode"><a href="#4-启动-DataNode" class="headerlink" title="4. 启动 DataNode"></a>4. 启动 DataNode</h3><p>在三台机器，执行以下代码进行启动 <code>datanode</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动 datanode</span></span><br><span class="line">[hadoop@hbase1(hbase2,hbase3) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start datanode</span><br></pre></td></tr></table></figure><p>然后在三台<code>datanode</code>分别查看相关进程信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]$ jps</span><br><span class="line">15792 NameNode</span><br><span class="line">15908 DFSZKFailoverController</span><br><span class="line">5339 Jps</span><br><span class="line">16014 DataNode</span><br><span class="line">15231 JournalNode</span><br></pre></td></tr></table></figure><p>查看返回信息，如果显示了 <code>DataNode</code>  进程，且查看日志没有发现相关错误信息，说明 <code>DataNode</code>  启动成功</p><p>查看 <code>DataNode</code>  日志信息(后边的 <code>hbase1</code> 是你的主机名称，其他两台根据实际情况更换主机名即可)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1 ~]# /var/log/hadoop/hadoop-hadoop-datanode-hbase1.log</span><br></pre></td></tr></table></figure><h2 id="初始化-HBase"><a href="#初始化-HBase" class="headerlink" title="初始化 HBase"></a>初始化 HBase</h2><blockquote><p>在首次启动 HBase 之前，请保证 hdfs 所有服务都处于开启状态，zookeeper 处于开启状态</p></blockquote><p>将 hbase 用户添加到 supergroup 组中</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# groupadd supergroup</span><br><span class="line">[root@localhost ~]# groupmems -g supergroup -a hbase</span><br></pre></td></tr></table></figure><p>切换到 hbase 用户</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[root@localhost ~]# su - hbase</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动 HMaster,只在第一台执行</span></span><br><span class="line">[hbase@hbase1 ~]# $HBASE_HOME/bin/hbase-daemon.sh start master</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动 HRegionserver，三台都执行</span></span><br><span class="line">[hbase@hbase1(hbase2,hbase3) ~]# $HBASE_HOME/bin/hbase-daemon.sh start regionserver</span><br></pre></td></tr></table></figure><p>然后在三台机器分别查看相关进程信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[hbase@hbase1 zookeeper]$ jps</span><br><span class="line">32628 HMaster</span><br><span class="line">5991 Jps</span><br><span class="line">3309 Main</span><br><span class="line">32383 HRegionServer</span><br></pre></td></tr></table></figure><p>查看返回信息，如果在第一台显示了 <code>Hmaster</code> 并且这三台都显示了 <code>HRegionServer</code>  进程，且查看日志没有发现相关错误信息，说明 <code>HRegionServer</code>  启动成功</p><p>查看 <code>HRegionServer</code>  日志信息(后边的 <code>hbase1</code> 是你的主机名称，其他两台根据实际情况更换主机名即可)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看 HMaster 日志信息</span></span><br><span class="line">[hbase@hbase1 ~]# tail -f /var/log/hbase/hbase-hbase-master-hbase1.log</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看 HRegionserver 日志信息</span></span><br><span class="line">[hbase@hbase1(hbase2,hbase3) ~]# tail -f /var/log/hbase/hbase-hbase-regionserver-hbase1.log</span><br></pre></td></tr></table></figure><h2 id="启动顺序"><a href="#启动顺序" class="headerlink" title="启动顺序"></a>启动顺序</h2><blockquote><p>注意：启动时必须按照启动顺序启动，否则可能会出现某些未知的启动失败的情况</p></blockquote><h3 id="Zookeeper-相关"><a href="#Zookeeper-相关" class="headerlink" title="Zookeeper 相关"></a>Zookeeper 相关</h3><p>先启动 <code>zookeeper</code> 。注意先切换到 zookeeper 用户后再进行启动！</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[zookeeper@hbase1(hbase2,hbase3) ~]# $ZOOKEEPER_HOME/bin/zkServer.sh start</span><br></pre></td></tr></table></figure><h3 id="Hadoop-相关"><a href="#Hadoop-相关" class="headerlink" title="Hadoop 相关"></a>Hadoop 相关</h3><p>再启动 <code>journalnode</code> 。注意先切换到 hadoop 用户后再进行启动！(hbase1,hbase2)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1(hbase2) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh start journalnode</span><br></pre></td></tr></table></figure><p>再启动 <code>namenode</code> 。注意先切换到 hadoop 用户后再进行启动！(hbase1,hbase2)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1(hbase2) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start namenode</span><br></pre></td></tr></table></figure><p>再启动 <code>zkfc</code> 。注意先切换到 hadoop 用户后再进行启动！(hbase1,hbase2)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1(hbase2) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start zkfc</span><br></pre></td></tr></table></figure><p>再启动 <code>datanode</code> 。注意先切换到 hadoop 用户后再进行启动！(hbase1,hbase2,hbase3)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hadoop@hbase1(hbase2,hbase3) ~]# $HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start datanode</span><br></pre></td></tr></table></figure><h3 id="HBase-相关"><a href="#HBase-相关" class="headerlink" title="HBase 相关"></a>HBase 相关</h3><p>再启动 <code>HMaster</code> 。注意先切换到 hbase 用户后再进行启动！(hbase1)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hbase@hbase1 ~]# $HBASE_HOME/bin/hbase-daemon.sh start master</span><br></pre></td></tr></table></figure><p>再启动 <code>HRegionServer</code> 。注意先切换到 hbase 用户后再进行启动！(hbase1,hbase2,hbase3)</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[hbase@hbase1(hbase2,hbase3) ~]# $HBASE_HOME/bin/hbase-daemon.sh start regionserver</span><br></pre></td></tr></table></figure><h2 id="关闭顺序"><a href="#关闭顺序" class="headerlink" title="关闭顺序"></a>关闭顺序</h2><blockquote><p>关闭顺序请参照启动顺序，反着来一边就可以</p></blockquote><h2 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Zookeeper相关</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动zookeeper集群</span></span><br><span class="line"><span class="meta">$</span><span class="bash">ZOOKEEPER_HOME/bin/zkServer.sh start</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看zookeeper集群状态</span></span><br><span class="line"><span class="meta">$</span><span class="bash">ZOOKEEPER_HOME/bin/zkServer.sh status</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 停止zookeeper集群</span></span><br><span class="line"><span class="meta">$</span><span class="bash">ZOOKEEPER_HOME/bin/zkServer.sh stop</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Hadoop相关</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动journalnode</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/sbin/hadoop-daemon.sh start journalnode</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 停止journalnode</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/sbin/hadoop-daemon.sh stop journalnode</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动namenode</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start namenode</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 停止namenode</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs stop namenode</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动zkfc</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start zkfc</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 停止zkfc</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs stop zkfc</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动datanode</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs start datanode</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 停止datanode</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HADOOP_HOME/sbin/hadoop-daemon.sh --script hdfs stop datanode</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> HBase相关</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动HMaster</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HBASE_HOME/bin/hbase-daemon.sh start master</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 停止HMaster</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HBASE_HOME/bin/hbase-daemon.sh stop master</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动HRegionServer</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HBASE_HOME/bin/hbase-daemon.sh start regionserver</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 停止HRegionServer</span></span><br><span class="line"><span class="meta">$</span><span class="bash">HBASE_HOME/bin/hbase-daemon.sh stop regionserver</span></span><br></pre></td></tr></table></figure>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HBase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Druid SQL解析工具的使用</title>
      <link href="/posts/6d9855d0/"/>
      <url>/posts/6d9855d0/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>最近在项目运行过程中，需要对标准SQL进行解析，然后对SQL进行改写，在各种查找对比后选中了Alibaba Druid来进行解析SQL（如非特制，以下均简称 Druid）</p><p>Druid官方的wiki说的还算明白，但可惜的是没有相关API文档。</p><h1 id="官方文档"><a href="#官方文档" class="headerlink" title="官方文档"></a>官方文档</h1><h2 id="1-SQL-Parser"><a href="#1-SQL-Parser" class="headerlink" title="1. SQL Parser"></a>1. SQL Parser</h2><p>如需查看原文：<a href="https://github.com/alibaba/druid/wiki/SQL-Parser" target="_blank" rel="noopener">SQL Parser</a></p><h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h3><p>SQL Parser是Druid的一个重要组成部分，Druid内置使用SQL Parser来实现防御SQL注入（<a href="https://github.com/alibaba/druid/wiki/%E7%AE%80%E4%BB%8B_WallFilter" target="_blank" rel="noopener">WallFilter</a>）、合并统计没有参数化的SQL(<a href="https://github.com/alibaba/druid/wiki/%E9%85%8D%E7%BD%AE_StatFilter" target="_blank" rel="noopener">StatFilter</a>的mergeSql)、<a href="https://github.com/alibaba/druid/wiki/SQL%E6%A0%BC%E5%BC%8F%E5%8C%96" target="_blank" rel="noopener">SQL格式化</a>、分库分表。</p><h4 id="1-1-和Antlr生成Parser的区别"><a href="#1-1-和Antlr生成Parser的区别" class="headerlink" title="1.1. 和Antlr生成Parser的区别"></a>1.1. 和Antlr生成Parser的区别</h4><p>和Antlr生成的SQL有很大不同的是，Druid SQL Parser性能非常好，可以用于生产环境直接对SQL进行分析处理。</p><h4 id="1-2-Druid-SQL-Parser的使用场景"><a href="#1-2-Druid-SQL-Parser的使用场景" class="headerlink" title="1.2. Druid SQL Parser的使用场景"></a>1.2. Druid SQL Parser的使用场景</h4><ul><li>MySql SQL全量统计</li><li>Hive/<a href="https://www.aliyun.com/product/odps" target="_blank" rel="noopener">ODPS</a> SQL执行安全审计</li><li>分库分表SQL解析引擎</li><li>数据库引擎的SQL Parser</li></ul><h3 id="2-各种语法支持"><a href="#2-各种语法支持" class="headerlink" title="2. 各种语法支持"></a>2. 各种语法支持</h3><p>Druid的sql parser是目前支持各种数据语法最完备的SQL Parser。目前对各种数据库的支持如下：</p><table><thead><tr><th>数据库</th><th>DML</th><th>DDL</th></tr></thead><tbody><tr><td><a href="https://www.aliyun.com/product/odps" target="_blank" rel="noopener">odps</a></td><td>完全支持</td><td>完全支持</td></tr><tr><td>mysql</td><td>完全支持</td><td>完全支持</td></tr><tr><td>postgresql</td><td>完全支持</td><td>完全支持</td></tr><tr><td>oracle</td><td>支持大部分</td><td>支持大部分</td></tr><tr><td>sql server</td><td>支持常用的</td><td>支持常用的ddl</td></tr><tr><td>db2</td><td>支持常用的</td><td>支持常用的ddl</td></tr><tr><td>hive</td><td>支持常用的</td><td>支持常用的ddl</td></tr></tbody></table><p>druid还缺省支持sql-92标准的语法，所以也部分支持其他数据库的sql语法。</p><h3 id="3-性能"><a href="#3-性能" class="headerlink" title="3. 性能"></a>3. 性能</h3><p>Druid的SQL Parser是手工编写，性能非常好，目标就是在生产环境运行时使用的SQL Parser，性能比antlr、javacc之类工具生成的Parser快10倍甚至100倍以上。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">ID</span>, <span class="keyword">NAME</span>, AGE <span class="keyword">FROM</span> <span class="keyword">USER</span> <span class="keyword">WHERE</span> <span class="keyword">ID</span> = ?</span><br></pre></td></tr></table></figure><p>这样的SQL，druid parser处理大约是600纳秒，也就是说单线程每秒可以处理1500万次以上。在1.1.3~1.1.4版本中，SQL Parser的性能有极大提升，完全可以适用于生产环境中对SQL进行处理。</p><h4 id="3-1-测试代码看这里"><a href="#3-1-测试代码看这里" class="headerlink" title="3.1. 测试代码看这里"></a>3.1. 测试代码看这里</h4><p><a href="https://github.com/alibaba/druid/blob/master/src/test/java/com/alibaba/druid/benckmark/sql/MySqlPerfTest.java" target="_blank" rel="noopener">MySqlPerfTest.java</a></p><h3 id="4-Druid-SQL-Parser的代码结构"><a href="#4-Druid-SQL-Parser的代码结构" class="headerlink" title="4. Druid SQL Parser的代码结构"></a>4. Druid SQL Parser的代码结构</h3><p>Druid SQL Parser分三个模块：</p><ul><li>Parser</li><li>AST</li><li>Visitor</li></ul><h4 id="4-1-parser"><a href="#4-1-parser" class="headerlink" title="4.1. parser"></a>4.1. parser</h4><p>parser是将输入文本转换为ast（抽象语法树），parser有包括两个部分，Parser和Lexer，其中Lexer实现词法分析，Parser实现语法分析。</p><h4 id="4-2-AST"><a href="#4-2-AST" class="headerlink" title="4.2. AST"></a>4.2. AST</h4><p>AST是Abstract Syntax Tree的缩写，也就是抽象语法树。AST是parser输出的结果。下面是获得抽象语法树的一个例子：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> String dbType = JdbcConstants.MYSQL; <span class="comment">// 可以是ORACLE、POSTGRESQL、SQLSERVER、ODPS等</span></span><br><span class="line">String sql = <span class="string">"select * from t"</span>;</span><br><span class="line">List&lt;SQLStatement&gt; stmtList = SQLUtils.parseStatements(sql, dbType);</span><br></pre></td></tr></table></figure><ul><li>Druid SQL AST介绍 <a href="https://github.com/alibaba/druid/wiki/Druid_SQL_AST" target="_blank" rel="noopener">https://github.com/alibaba/druid/wiki/Druid_SQL_AST</a></li></ul><h4 id="4-3-Visitor"><a href="#4-3-Visitor" class="headerlink" title="4.3. Visitor"></a>4.3. Visitor</h4><p>Visitor是遍历AST的手段，是处理AST最方便的模式，Visitor是一个接口，有缺省什么都没做的实现VistorAdapter。</p><p>我们可以实现不同的Visitor来满足不同的需求，Druid内置提供了如下Visitor: </p><ul><li>OutputVisitor用来把AST输出为字符串</li><li><a href="https://github.com/alibaba/druid/wiki/%E7%AE%80%E4%BB%8B_WallFilter" target="_blank" rel="noopener">WallVisitor</a> 来分析SQL语意来防御SQL注入攻击</li><li>ParameterizedOutputVisitor用来合并未参数化的SQL进行统计</li><li><a href="https://github.com/alibaba/druid/wiki/EvalVisitor" target="_blank" rel="noopener">EvalVisitor</a> 用来对SQL表达式求值</li><li>ExportParameterVisitor用来提取SQL中的变量参数</li><li><a href="https://github.com/alibaba/druid/wiki/SchemaStatVisitor" target="_blank" rel="noopener">SchemaStatVisitor</a> 用来统计SQL中使用的表、字段、过滤条件、排序表达式、分组表达式</li><li><a href="https://github.com/alibaba/druid/wiki/SQL_Format" target="_blank" rel="noopener">SQL格式化</a> Druid内置了基于语义的SQL格式化功能</li></ul><h4 id="4-4-自定义Visitor"><a href="#4-4-自定义Visitor" class="headerlink" title="4.4. 自定义Visitor"></a>4.4. 自定义Visitor</h4><p>每种方言的Visitor都有一个缺省的VisitorAdapter，使得编写自定义的Visitor更方便。<br><a href="https://github.com/alibaba/druid/wiki/SQL_Parser_Demo_visitor" target="_blank" rel="noopener">https://github.com/alibaba/druid/wiki/SQL_Parser_Demo_visitor</a></p><h4 id="4-5-自定义visitor示例"><a href="#4-5-自定义visitor示例" class="headerlink" title="4.5 自定义visitor示例"></a>4.5 自定义visitor示例</h4><h5 id="1-实现自己的Visitor"><a href="#1-实现自己的Visitor" class="headerlink" title="1. 实现自己的Visitor"></a>1. 实现自己的Visitor</h5><h6 id="1-1-Oracle版本"><a href="#1-1-Oracle版本" class="headerlink" title="1.1 Oracle版本"></a>1.1 Oracle版本</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ExportTableAliasVisitor</span> <span class="keyword">extends</span> <span class="title">OracleASTVisitorAdapter</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, SQLTableSource&gt; aliasMap = <span class="keyword">new</span> HashMap&lt;String, SQLTableSource&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">visit</span><span class="params">(OracleSelectTableReference x)</span> </span>&#123;</span><br><span class="line">        String alias = x.getAlias();</span><br><span class="line">        aliasMap.put(alias, x);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String, SQLTableSource&gt; <span class="title">getAliasMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> aliasMap;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="1-2-MySql版本"><a href="#1-2-MySql版本" class="headerlink" title="1.2 MySql版本"></a>1.2 MySql版本</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ExportTableAliasVisitor</span> <span class="keyword">extends</span> <span class="title">MySqlASTVisitorAdapter</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, SQLTableSource&gt; aliasMap = <span class="keyword">new</span> HashMap&lt;String, SQLTableSource&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">visit</span><span class="params">(SQLExprTableSource x)</span> </span>&#123;</span><br><span class="line">        String alias = x.getAlias();</span><br><span class="line">        aliasMap.put(alias, x);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String, SQLTableSource&gt; <span class="title">getAliasMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> aliasMap;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h6 id="1-3-POSTGRESQL版本"><a href="#1-3-POSTGRESQL版本" class="headerlink" title="1.3 POSTGRESQL版本"></a>1.3 POSTGRESQL版本</h6><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ExportTableAliasVisitor</span> <span class="keyword">extends</span> <span class="title">PGASTVisitorAdapter</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, SQLTableSource&gt; aliasMap = <span class="keyword">new</span> HashMap&lt;String, SQLTableSource&gt;();</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">visit</span><span class="params">(SQLExprTableSource x)</span> </span>&#123;</span><br><span class="line">        String alias = x.getAlias();</span><br><span class="line">        aliasMap.put(alias, x);</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Map&lt;String, SQLTableSource&gt; <span class="title">getAliasMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> aliasMap;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="2-使用Visitor"><a href="#2-使用Visitor" class="headerlink" title="2. 使用Visitor"></a>2. 使用Visitor</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">finnal String dbType = JdbcConstants.ORACLE; <span class="comment">// JdbcConstants.MYSQL或者JdbcConstants.POSTGRESQL</span></span><br><span class="line">String sql = <span class="string">"select * from mytable a where a.id = 3"</span>;</span><br><span class="line">List&lt;SQLStatement&gt; stmtList = SQLUtils.parseStatements(sql, dbType);</span><br><span class="line"></span><br><span class="line">ExportTableAliasVisitor visitor = <span class="keyword">new</span> ExportTableAliasVisitor();</span><br><span class="line"><span class="keyword">for</span> (SQLStatement stmt : stmtList) &#123;</span><br><span class="line">    stmt.accept(visitor);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">SQLTableSource tableSource = visitor.getAliasMap().get(<span class="string">"a"</span>);</span><br><span class="line">System.out.println(tableSource);</span><br></pre></td></tr></table></figure><h4 id="4-6-方言"><a href="#4-6-方言" class="headerlink" title="4.6. 方言"></a>4.6. 方言</h4><p>SQL-92、SQL-99等都是标准SQL，mysql/oracle/pg/sqlserver/odps等都是方言，也就是dialect。parser/ast/visitor都需要针对不同的方言进行特别处理。</p><h3 id="5-SchemaRepository"><a href="#5-SchemaRepository" class="headerlink" title="5. SchemaRepository"></a>5. SchemaRepository</h3><p>Druid SQL Parser内置了一个SchemaRepository，在内存中缓存SQL Schema信息，用于SQL语义解析中的ColumnResolve等操作。<br><a href="https://github.com/alibaba/druid/wiki/SQL_Schema_Repository" target="_blank" rel="noopener">https://github.com/alibaba/druid/wiki/SQL_Schema_Repository</a></p><h3 id="6-SQL翻译"><a href="#6-SQL翻译" class="headerlink" title="6. SQL翻译"></a>6. SQL翻译</h3><p>可以基于Druid SQL Parser之上构造Oracle SQL到其他数据的SQL翻译。比如Aliyun提供的Oracle到MySql的<a href="https://rainbow-expert.aliyun.com/sqltransform.htm" target="_blank" rel="noopener">SQL翻译功能</a>，就是基于Druid基础上实现的。<a href="https://rainbow-expert.aliyun.com/sqltransform.htm" target="_blank" rel="noopener">https://rainbow-expert.aliyun.com/sqltransform.htm</a></p><h2 id="2-SQL-Formatter"><a href="#2-SQL-Formatter" class="headerlink" title="2. SQL Formatter"></a>2. SQL Formatter</h2><p>Druid SQL Parser提供了格式化代码的工具类。这个是基于语义分析做的SQL格式化功能，比其他的SQL格式化做的更智能，效果更好。</p><h3 id="格式化的工具类API"><a href="#格式化的工具类API" class="headerlink" title="格式化的工具类API"></a>格式化的工具类API</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.alibaba.druid.sql;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SQLUtils</span> </span>&#123;</span><br><span class="line">    <span class="function">String <span class="title">format</span><span class="params">(String sq, String dbType)</span></span>;</span><br><span class="line">    <span class="function">String <span class="title">format</span><span class="params">(String sq, String dbType, FormatOption option)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>其中dbType支持mysql/postgresql/odps/oracle/db2/sqlserver</li><li>option缺省有SQLUtils.DEFAULT_FORMAT_OPTION（大写）、SQLUtils.DEFAULT_LCASE_FORMAT_OPTION（小写）两种可以选择，也可按需要定制化。</li></ul><h3 id="MySQL-格式化"><a href="#MySQL-格式化" class="headerlink" title="MySQL 格式化"></a>MySQL 格式化</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.druid.sql.SQLUtils;</span><br><span class="line"><span class="keyword">import</span> com.alibaba.druid.util.JdbcConstants;</span><br><span class="line"></span><br><span class="line">String sql = <span class="string">"update t set name = 'x' where id &lt; 100 limit 10"</span>;</span><br><span class="line">String result = SQLUtils.format(sql, JdbcConstants.MYSQL);</span><br><span class="line">System.out.println(result); <span class="comment">// 缺省大写格式</span></span><br><span class="line"></span><br><span class="line">String result_lcase = SQLUtils.format(sql</span><br><span class="line">                         , JdbcConstants.MYSQL</span><br><span class="line">                         , SQLUtils.DEFAULT_LCASE_FORMAT_OPTION);</span><br><span class="line">System.out.println(result_lcase); <span class="comment">// 小写格式</span></span><br></pre></td></tr></table></figure><p>输出格式化后的结果：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 这是缺省的大写格式</span></span><br><span class="line"><span class="keyword">UPDATE</span> t</span><br><span class="line"><span class="keyword">SET</span> <span class="keyword">name</span> = <span class="string">'x'</span></span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">id</span> &lt; <span class="number">100</span></span><br><span class="line"><span class="keyword">LIMIT</span> <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment">-- 这是小写格式</span></span><br><span class="line"><span class="keyword">update</span> t</span><br><span class="line"><span class="keyword">set</span> <span class="keyword">name</span> = <span class="string">'x'</span></span><br><span class="line"><span class="keyword">where</span> <span class="keyword">id</span> &lt; <span class="number">100</span></span><br><span class="line"><span class="keyword">limit</span> <span class="number">10</span></span><br></pre></td></tr></table></figure><h2 id="3-SQL-Schema-Repository"><a href="#3-SQL-Schema-Repository" class="headerlink" title="3. SQL Schema Repository"></a>3. SQL Schema Repository</h2><h3 id="1-简介-1"><a href="#1-简介-1" class="headerlink" title="1. 简介"></a>1. 简介</h3><p>Druid SQL Parser内置了一个SchemaRepository，在内存中缓存SQL Schema信息，用于SQL语义解析中的ColumnResolve等操作。</p><h3 id="2-如何使用SchemaRepository"><a href="#2-如何使用SchemaRepository" class="headerlink" title="2. 如何使用SchemaRepository"></a>2. 如何使用SchemaRepository</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.druid.sql.repository.SchemaRepository;</span><br><span class="line"></span><br><span class="line"><span class="comment">// SchemaRepository是和数据库类型相关的，构造时需要传入dbType</span></span><br><span class="line"><span class="keyword">final</span> String dbType = JdbcConstants.MYSQL;</span><br><span class="line">SchemaRepository repository = <span class="keyword">new</span> SchemaRepository(dbType);</span><br><span class="line"></span><br><span class="line">repository.console(<span class="string">"use sc00;"</span>);</span><br><span class="line"></span><br><span class="line">String sql = <span class="string">"CREATE TABLE `test1` (\n"</span> +</span><br><span class="line">        <span class="string">"  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT 'id',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_tinyint` tinyint(4) DEFAULT '1' COMMENT 'tinyint',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_smallint` smallint(6) DEFAULT 0 COMMENT 'smallint',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_mediumint` mediumint(9) DEFAULT NULL COMMENT 'mediumint',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_int` int(11) DEFAULT NULL COMMENT 'int',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_bigint` bigint(20) DEFAULT NULL COMMENT 'bigint',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_decimal` decimal(10,3) DEFAULT NULL COMMENT 'decimal',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_date` date DEFAULT '0000-00-00' COMMENT 'date',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_datetime` datetime DEFAULT '0000-00-00 00:00:00' COMMENT 'datetime',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_timestamp` timestamp NULL DEFAULT NULL COMMENT 'timestamp'  ON UPDATE CURRENT_TIMESTAMP ,\n"</span> +</span><br><span class="line">        <span class="string">"  `c_time` time DEFAULT NULL COMMENT 'time',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_char` char(10) DEFAULT NULL COMMENT 'char',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_varchar` varchar(10) DEFAULT 'hello' COMMENT 'varchar',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_blob` blob COMMENT 'blob',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_text` text COMMENT 'text',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_mediumtext` mediumtext COMMENT 'mediumtext',\n"</span> +</span><br><span class="line">        <span class="string">"  `c_longblob` longblob COMMENT 'longblob',\n"</span> +</span><br><span class="line">        <span class="string">"  PRIMARY KEY (`id`,`c_tinyint`),\n"</span> +</span><br><span class="line">        <span class="string">"  UNIQUE KEY `uk_a` (`c_varchar`,`c_mediumint`),\n"</span> +</span><br><span class="line">        <span class="string">"  KEY `k_c` (`c_tinyint`,`c_int`),\n"</span> +</span><br><span class="line">        <span class="string">"  KEY `k_d` (`c_char`,`c_bigint`)\n"</span> +</span><br><span class="line">        <span class="string">") ENGINE=InnoDB AUTO_INCREMENT=1769503 DEFAULT CHARSET=utf8mb4 COMMENT='10000000'"</span>;</span><br><span class="line"></span><br><span class="line">repository.console(sql);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在如下的代码中可以知道repository中已经存在表test1</span></span><br><span class="line">MySqlCreateTableStatement createTableStmt = (MySqlCreateTableStatement) repository.findTable(<span class="string">"test1"</span>).getStatement();</span><br><span class="line">assertEquals(<span class="number">21</span>, createTableStmt.getTableElementList().size());</span><br><span class="line"></span><br><span class="line"><span class="comment">// 通过执行命令"show columns from test1"可以获得mysql console风格的输出</span></span><br><span class="line">assertEquals(<span class="string">"+--------------+---------------+------+-----+---------------------+-----------------------------+\n"</span> +</span><br><span class="line">        <span class="string">"| Field        | Type          | Null | Key | Default             | Extra                       |\n"</span> +</span><br><span class="line">        <span class="string">"+--------------+---------------+------+-----+---------------------+-----------------------------+\n"</span> +</span><br><span class="line">        <span class="string">"| id           | bigint(20)    | NO   | PRI | NULL                | auto_increment              |\n"</span> +</span><br><span class="line">        <span class="string">"| c_tinyint    | tinyint(4)    | YES  | PRI | 1                   |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_smallint   | smallint(6)   | YES  |     | 0                   |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_mediumint  | mediumint(9)  | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_int        | int(11)       | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_bigint     | bigint(20)    | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_decimal    | decimal(10,3) | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_date       | date          | YES  |     | 0000-00-00          |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_datetime   | datetime      | YES  |     | 0000-00-00 00:00:00 |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_timestamp  | timestamp     | YES  |     | NULL                | on update CURRENT_TIMESTAMP |\n"</span> +</span><br><span class="line">        <span class="string">"| c_time       | time          | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_char       | char(10)      | YES  | MUL | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_varchar    | varchar(10)   | YES  | MUL | hello               |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_blob       | blob          | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_text       | text          | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_mediumtext | mediumtext    | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_longblob   | longblob      | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"+--------------+---------------+------+-----+---------------------+-----------------------------+\n"</span>, </span><br><span class="line">repository.console(<span class="string">"show columns from test1"</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 执行alter语句，修改repository中内容</span></span><br><span class="line">repository.console(<span class="string">"alter table test1 drop column c_decimal;"</span>);</span><br><span class="line">assertEquals(<span class="number">20</span>, createTableStmt.getTableElementList().size());</span><br><span class="line"></span><br><span class="line">assertEquals(<span class="string">"+--------------+--------------+------+-----+---------------------+-----------------------------+\n"</span> +</span><br><span class="line">        <span class="string">"| Field        | Type         | Null | Key | Default             | Extra                       |\n"</span> +</span><br><span class="line">        <span class="string">"+--------------+--------------+------+-----+---------------------+-----------------------------+\n"</span> +</span><br><span class="line">        <span class="string">"| id           | bigint(20)   | NO   | PRI | NULL                | auto_increment              |\n"</span> +</span><br><span class="line">        <span class="string">"| c_tinyint    | tinyint(4)   | YES  | PRI | 1                   |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_smallint   | smallint(6)  | YES  |     | 0                   |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_mediumint  | mediumint(9) | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_int        | int(11)      | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_bigint     | bigint(20)   | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_date       | date         | YES  |     | 0000-00-00          |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_datetime   | datetime     | YES  |     | 0000-00-00 00:00:00 |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_timestamp  | timestamp    | YES  |     | NULL                | on update CURRENT_TIMESTAMP |\n"</span> +</span><br><span class="line">        <span class="string">"| c_time       | time         | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_char       | char(10)     | YES  | MUL | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_varchar    | varchar(10)  | YES  | MUL | hello               |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_blob       | blob         | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_text       | text         | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_mediumtext | mediumtext   | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"| c_longblob   | longblob     | YES  |     | NULL                |                             |\n"</span> +</span><br><span class="line">        <span class="string">"+--------------+--------------+------+-----+---------------------+-----------------------------+\n"</span>, </span><br><span class="line">repository.console(<span class="string">"show columns from test1"</span>));</span><br></pre></td></tr></table></figure><h3 id="3-Column-Resolve"><a href="#3-Column-Resolve" class="headerlink" title="3. Column Resolve"></a>3. Column Resolve</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> String dbType = JdbcConstants.MYSQL;</span><br><span class="line"></span><br><span class="line">SchemaRepository repository = <span class="keyword">new</span> SchemaRepository(dbType);</span><br><span class="line"></span><br><span class="line">repository.console(<span class="string">"create table t_emp(emp_id bigint, name varchar(20));"</span>);</span><br><span class="line">repository.console(<span class="string">"create table t_org(org_id bigint, name varchar(20));"</span>);</span><br><span class="line"></span><br><span class="line">String sql = <span class="string">"SELECT emp_id, a.name AS emp_name, org_id, b.name AS org_name\n"</span> +</span><br><span class="line">        <span class="string">"FROM t_emp a\n"</span> +</span><br><span class="line">        <span class="string">"\tINNER JOIN t_org b ON a.emp_id = b.org_id"</span>;</span><br><span class="line"></span><br><span class="line">List&lt;SQLStatement&gt; stmtList = SQLUtils.parseStatements(sql, dbType);</span><br><span class="line">assertEquals(<span class="number">1</span>, stmtList.size());</span><br><span class="line"></span><br><span class="line">SQLSelectStatement stmt = (SQLSelectStatement) stmtList.get(<span class="number">0</span>);</span><br><span class="line">SQLSelectQueryBlock queryBlock = stmt.getSelect().getQueryBlock();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 大小写不敏感</span></span><br><span class="line">assertNotNull(queryBlock.findTableSource(<span class="string">"A"</span>));</span><br><span class="line">assertSame(queryBlock.findTableSource(<span class="string">"a"</span>), queryBlock.findTableSource(<span class="string">"A"</span>));</span><br><span class="line"></span><br><span class="line">assertNull(queryBlock.findTableSourceWithColumn(<span class="string">"emp_id"</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 使用repository做column resolve</span></span><br><span class="line">repository.resolve(stmt);</span><br><span class="line"></span><br><span class="line">assertNotNull(queryBlock.findTableSourceWithColumn(<span class="string">"emp_id"</span>));</span><br><span class="line"></span><br><span class="line">SQLExprTableSource tableSource = (SQLExprTableSource) queryBlock.findTableSourceWithColumn(<span class="string">"emp_id"</span>);</span><br><span class="line">assertNotNull(tableSource.getSchemaObject());</span><br><span class="line"></span><br><span class="line">SQLCreateTableStatement createTableStmt = (SQLCreateTableStatement) tableSource.getSchemaObject().getStatement();</span><br><span class="line">assertNotNull(createTableStmt);</span><br><span class="line"></span><br><span class="line">SQLSelectItem selectItem = queryBlock.findSelectItem(<span class="string">"org_name"</span>);</span><br><span class="line">assertNotNull(selectItem);</span><br><span class="line">SQLPropertyExpr selectItemExpr = (SQLPropertyExpr) selectItem.getExpr();</span><br><span class="line">SQLColumnDefinition column = selectItemExpr.getResolvedColumn();</span><br><span class="line">assertNotNull(column);</span><br><span class="line">assertEquals(<span class="string">"name"</span>, column.getName().toString());</span><br><span class="line">assertEquals(<span class="string">"t_org"</span>, (((SQLCreateTableStatement)column.getParent()).getName().toString()));</span><br><span class="line"></span><br><span class="line">assertSame(queryBlock.findTableSource(<span class="string">"B"</span>), selectItemExpr.getResolvedTableSource());</span><br></pre></td></tr></table></figure><h2 id="4-SQL-Parser-Parameterize"><a href="#4-SQL-Parser-Parameterize" class="headerlink" title="4. SQL Parser Parameterize"></a>4. SQL Parser Parameterize</h2><h3 id="1-功能介绍"><a href="#1-功能介绍" class="headerlink" title="1. 功能介绍"></a>1. 功能介绍</h3><p>如果要对SQL做各种统计，通常需要对SQL进行参数化再做统计。比如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">// 原始SQL</span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">id</span> = <span class="number">1</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">id</span> = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">// 参数化<span class="keyword">SQL</span></span><br><span class="line"><span class="keyword">select</span> * <span class="keyword">from</span> t <span class="keyword">where</span> <span class="keyword">id</span> = ?</span><br></pre></td></tr></table></figure><h3 id="2-SQL参数化"><a href="#2-SQL参数化" class="headerlink" title="2. SQL参数化"></a>2. SQL参数化</h3><h4 id="2-1-SQL参数化API"><a href="#2-1-SQL参数化API" class="headerlink" title="2.1 SQL参数化API"></a>2.1 SQL参数化API</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.alibaba.druid.sql.visitor;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ParameterizedOutputVisitorUtils</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">parameterize</span><span class="params">(String sql, String dbType)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-2-SQL参数化DEMO"><a href="#2-2-SQL参数化DEMO" class="headerlink" title="2.2 SQL参数化DEMO"></a>2.2 SQL参数化DEMO</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.druid.sql.visitor.ParameterizedOutputVisitorUtils;</span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> String dbType = JdbcConstants.MYSQL;</span><br><span class="line"></span><br><span class="line">String sql = <span class="string">"select * from t where id = 1 or id = 2 or id = 3"</span>;</span><br><span class="line">String psql = ParameterizedOutputVisitorUtils.parameterize(sql, dbType);</span><br><span class="line">assertEquals(<span class="string">"SELECT *\n"</span> +</span><br><span class="line">        <span class="string">"FROM t\n"</span> +</span><br><span class="line">        <span class="string">"WHERE id = ?"</span>, psql);</span><br></pre></td></tr></table></figure><h4 id="3-获取具体参数化后的常量值"><a href="#3-获取具体参数化后的常量值" class="headerlink" title="3. 获取具体参数化后的常量值"></a>3. 获取具体参数化后的常量值</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> String dbType = JdbcConstants.MYSQL;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 参数化SQL是输出的参数保存在这个List中</span></span><br><span class="line">List&lt;Object&gt; outParameters = <span class="keyword">new</span> ArrayList&lt;Object&gt;();</span><br><span class="line"></span><br><span class="line">String sql = <span class="string">"select * from t where id = 101 and age = 102 or name = 'wenshao'"</span>;</span><br><span class="line">String psql = ParameterizedOutputVisitorUtils.parameterize(sql, dbType, outParameters);</span><br><span class="line">assertEquals(<span class="string">"SELECT *\n"</span> +</span><br><span class="line">        <span class="string">"FROM t\n"</span> +</span><br><span class="line">        <span class="string">"WHERE id = ?\n"</span> +</span><br><span class="line">        <span class="string">"\tAND age = ?\n"</span> +</span><br><span class="line">        <span class="string">"\tOR name = ?"</span>, psql);</span><br><span class="line"></span><br><span class="line">assertEquals(<span class="number">3</span>, outParameters.size());</span><br><span class="line">assertEquals(<span class="number">101</span>, outParameters.get(<span class="number">0</span>));</span><br><span class="line">assertEquals(<span class="number">102</span>, outParameters.get(<span class="number">1</span>));</span><br><span class="line">assertEquals(<span class="string">"wenshao"</span>, outParameters.get(<span class="number">2</span>));</span><br></pre></td></tr></table></figure><h2 id="5-Druid-SQL-AST"><a href="#5-Druid-SQL-AST" class="headerlink" title="5. Druid SQL AST"></a>5. Druid SQL AST</h2><h3 id="1-什么是AST"><a href="#1-什么是AST" class="headerlink" title="1. 什么是AST"></a>1. 什么是AST</h3><p>AST是abstract syntax tree的缩写，也就是抽象语法树。和所有的Parser一样，Druid Parser会生成一个抽象语法树。</p><h3 id="2-在Druid-SQL-Parser中有哪些AST节点类型"><a href="#2-在Druid-SQL-Parser中有哪些AST节点类型" class="headerlink" title="2. 在Druid SQL Parser中有哪些AST节点类型"></a>2. 在Druid SQL Parser中有哪些AST节点类型</h3><p>在Druid中，AST节点类型主要包括SQLObject、SQLExpr、SQLStatement三种抽象类型。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.alibaba.druid.sql.ast;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">SQLObject</span> </span>&#123;&#125;</span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">SQLExpr</span> <span class="keyword">extends</span> <span class="title">SQLObject</span> </span>&#123;&#125;</span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">SQLStatement</span> <span class="keyword">extends</span> <span class="title">SQLObject</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">SQLTableSource</span> <span class="keyword">extends</span> <span class="title">SQLObject</span> </span>&#123;&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLSelect</span> <span class="keyword">extends</span> <span class="title">SQLObject</span> </span>&#123;&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLSelectQueryBlock</span> <span class="keyword">extends</span> <span class="title">SQLObject</span> </span>&#123;&#125;</span><br></pre></td></tr></table></figure><h4 id="2-1-常用的SQLExpr有哪些"><a href="#2-1-常用的SQLExpr有哪些" class="headerlink" title="2.1. 常用的SQLExpr有哪些"></a>2.1. 常用的SQLExpr有哪些</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.alibaba.druid.sql.ast.expr;</span><br><span class="line"></span><br><span class="line"><span class="comment">// SQLName是一种的SQLExpr的Expr，包括SQLIdentifierExpr、SQLPropertyExpr等</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">SQLName</span> <span class="keyword">extends</span> <span class="title">SQLExpr</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 ID = 3 这里的ID是一个SQLIdentifierExpr</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLIdentifierExpr</span> <span class="keyword">implements</span> <span class="title">SQLExpr</span>, <span class="title">SQLName</span> </span>&#123;</span><br><span class="line">    String name;</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 A.ID = 3 这里的A.ID是一个SQLPropertyExpr</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLPropertyExpr</span> <span class="keyword">implements</span> <span class="title">SQLExpr</span>, <span class="title">SQLName</span> </span>&#123;</span><br><span class="line">    SQLExpr owner;</span><br><span class="line">    String name;</span><br><span class="line">&#125; </span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 ID = 3 这是一个SQLBinaryOpExpr</span></span><br><span class="line"><span class="comment">// left是ID (SQLIdentifierExpr)</span></span><br><span class="line"><span class="comment">// right是3 (SQLIntegerExpr)</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLBinaryOpExpr</span> <span class="keyword">implements</span> <span class="title">SQLExpr</span> </span>&#123;</span><br><span class="line">    SQLExpr left;</span><br><span class="line">    SQLExpr right;</span><br><span class="line">    SQLBinaryOperator operator;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 select * from where id = ?，这里的?是一个SQLVariantRefExpr，name是'?'</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLVariantRefExpr</span> <span class="keyword">extends</span> <span class="title">SQLExprImpl</span> </span>&#123; </span><br><span class="line">    String name;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 ID = 3 这里的3是一个SQLIntegerExpr</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SQLIntegerExpr</span> <span class="keyword">extends</span> <span class="title">SQLNumericLiteralExpr</span> <span class="keyword">implements</span> <span class="title">SQLValuableExpr</span> </span>&#123; </span><br><span class="line">    Number number;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 所有实现了SQLValuableExpr接口的SQLExpr都可以直接调用这个方法求值</span></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">getValue</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">this</span>.number;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 NAME = 'jobs' 这里的'jobs'是一个SQLCharExpr</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SQLCharExpr</span> <span class="keyword">extends</span> <span class="title">SQLTextLiteralExpr</span> <span class="keyword">implements</span> <span class="title">SQLValuableExpr</span></span>&#123;</span><br><span class="line">    String text;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-2-常用的SQLStatemment"><a href="#2-2-常用的SQLStatemment" class="headerlink" title="2.2. 常用的SQLStatemment"></a>2.2. 常用的SQLStatemment</h4><p>最常用的Statement当然是SELECT/UPDATE/DELETE/INSERT，他们分别是</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.alibaba.druid.sql.ast.statement;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLSelectStatement</span> <span class="keyword">implements</span> <span class="title">SQLStatement</span> </span>&#123;</span><br><span class="line">    SQLSelect select;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLUpdateStatement</span> <span class="keyword">implements</span> <span class="title">SQLStatement</span> </span>&#123;</span><br><span class="line">    SQLExprTableSource tableSource;</span><br><span class="line">     List&lt;SQLUpdateSetItem&gt; items;</span><br><span class="line">     SQLExpr where;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLDeleteStatement</span> <span class="keyword">implements</span> <span class="title">SQLStatement</span> </span>&#123;</span><br><span class="line">    SQLTableSource tableSource; </span><br><span class="line">    SQLExpr where;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLInsertStatement</span> <span class="keyword">implements</span> <span class="title">SQLStatement</span> </span>&#123;</span><br><span class="line">    SQLExprTableSource tableSource;</span><br><span class="line">    List&lt;SQLExpr&gt; columns;</span><br><span class="line">    SQLSelect query;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-3-SQLTableSource"><a href="#2-3-SQLTableSource" class="headerlink" title="2.3. SQLTableSource"></a>2.3. SQLTableSource</h4><p>常见的SQLTableSource包括SQLExprTableSource、SQLJoinTableSource、SQLSubqueryTableSource、SQLWithSubqueryClause.Entry</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLTableSourceImpl</span> <span class="keyword">extends</span> <span class="title">SQLObjectImpl</span> <span class="keyword">implements</span> <span class="title">SQLTableSource</span> </span>&#123; </span><br><span class="line">    String alias;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 select * from emp where i = 3，这里的from emp是一个SQLExprTableSource</span></span><br><span class="line"><span class="comment">// 其中expr是一个name=emp的SQLIdentifierExpr</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLExprTableSource</span> <span class="keyword">extends</span> <span class="title">SQLTableSourceImpl</span> </span>&#123;</span><br><span class="line">    SQLExpr expr;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 select * from emp e inner join org o on e.org_id = o.id</span></span><br><span class="line"><span class="comment">// 其中left 'emp e' 是一个SQLExprTableSource，right 'org o'也是一个SQLExprTableSource</span></span><br><span class="line"><span class="comment">// condition 'e.org_id = o.id'是一个SQLBinaryOpExpr</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLJoinTableSource</span> <span class="keyword">extends</span> <span class="title">SQLTableSourceImpl</span> </span>&#123;</span><br><span class="line">    SQLTableSource left;</span><br><span class="line">    SQLTableSource right;</span><br><span class="line">    JoinType joinType; <span class="comment">// INNER_JOIN/CROSS_JOIN/LEFT_OUTER_JOIN/RIGHT_OUTER_JOIN/...</span></span><br><span class="line">    SQLExpr condition;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 例如 select * from (select * from temp) a，这里第一层from(...)是一个SQLSubqueryTableSource</span></span><br><span class="line">SQLSubqueryTableSource extends SQLTableSourceImpl &#123;</span><br><span class="line">    SQLSelect select;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* </span></span><br><span class="line"><span class="comment">例如</span></span><br><span class="line"><span class="comment">WITH RECURSIVE ancestors AS (</span></span><br><span class="line"><span class="comment">    SELECT *</span></span><br><span class="line"><span class="comment">    FROM org</span></span><br><span class="line"><span class="comment">    UNION</span></span><br><span class="line"><span class="comment">    SELECT f.*</span></span><br><span class="line"><span class="comment">    FROM org f, ancestors a</span></span><br><span class="line"><span class="comment">    WHERE f.id = a.parent_id</span></span><br><span class="line"><span class="comment">)</span></span><br><span class="line"><span class="comment">SELECT *</span></span><br><span class="line"><span class="comment">FROM ancestors;</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">这里的ancestors AS (...) 是一个SQLWithSubqueryClause.Entry</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLWithSubqueryClause</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Entry</span> <span class="keyword">extends</span> <span class="title">SQLTableSourceImpl</span> </span>&#123; </span><br><span class="line">         SQLSelect subQuery;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-4-SQLSelect-amp-SQLSelectQuery"><a href="#2-4-SQLSelect-amp-SQLSelectQuery" class="headerlink" title="2.4. SQLSelect &amp; SQLSelectQuery"></a>2.4. SQLSelect &amp; SQLSelectQuery</h4><p>SQLSelectStatement包含一个SQLSelect，SQLSelect包含一个SQLSelectQuery，都是组成的关系。SQLSelectQuery有主要的两个派生类，分别是SQLSelectQueryBlock和SQLUnionQuery。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLSelect</span> <span class="keyword">extends</span> <span class="title">SQLObjectImpl</span> </span>&#123; </span><br><span class="line">    SQLWithSubqueryClause withSubQuery;</span><br><span class="line">    SQLSelectQuery query;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">interface</span> <span class="title">SQLSelectQuery</span> <span class="keyword">extends</span> <span class="title">SQLObject</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLSelectQueryBlock</span> <span class="keyword">implements</span> <span class="title">SQLSelectQuery</span> </span>&#123;</span><br><span class="line">    List&lt;SQLSelectItem&gt; selectList;</span><br><span class="line">    SQLTableSource from;</span><br><span class="line">    SQLExprTableSource into;</span><br><span class="line">    SQLExpr where;</span><br><span class="line">    SQLSelectGroupByClause groupBy;</span><br><span class="line">    SQLOrderBy orderBy;</span><br><span class="line">    SQLLimit limit;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">SQLUnionQuery</span> <span class="keyword">implements</span> <span class="title">SQLSelectQuery</span> </span>&#123;</span><br><span class="line">    SQLSelectQuery left;</span><br><span class="line">    SQLSelectQuery right;</span><br><span class="line">    SQLUnionOperator operator; <span class="comment">// UNION/UNION_ALL/MINUS/INTERSECT</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="2-5-SQLCreateTableStatement"><a href="#2-5-SQLCreateTableStatement" class="headerlink" title="2.5. SQLCreateTableStatement"></a>2.5. SQLCreateTableStatement</h4><p>建表语句包含了一系列方法，用于方便各种操作</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SQLCreateTableStatement</span> <span class="keyword">extends</span> <span class="title">SQLStatementImpl</span> <span class="keyword">implements</span> <span class="title">SQLDDLStatement</span>, <span class="title">SQLCreateStatement</span> </span>&#123;</span><br><span class="line">    SQLExprTableSource tableSource;</span><br><span class="line">    List&lt;SQLTableElement&gt; tableElementList;</span><br><span class="line">    Select select;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 忽略大小写的查找SQLCreateTableStatement中的SQLColumnDefinition</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SQLColumnDefinition <span class="title">findColumn</span><span class="params">(String columName)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 忽略大小写的查找SQLCreateTableStatement中的column关联的索引</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SQLTableElement <span class="title">findIndex</span><span class="params">(String columnName)</span> </span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 是否外键依赖另外一个表</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isReferenced</span><span class="params">(String tableName)</span> </span>&#123;&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-怎样产生AST"><a href="#3-怎样产生AST" class="headerlink" title="3. 怎样产生AST"></a>3. 怎样产生AST</h3><h4 id="3-1-通过SQLUtils产生List-lt-SQLStatement-gt"><a href="#3-1-通过SQLUtils产生List-lt-SQLStatement-gt" class="headerlink" title="3.1. 通过SQLUtils产生List&lt;SQLStatement&gt;"></a>3.1. 通过SQLUtils产生List&lt;SQLStatement&gt;</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.alibaba.druid.util.JdbcConstants;</span><br><span class="line"></span><br><span class="line">String dbType = JdbcConstants.MYSQL;</span><br><span class="line">List&lt;SQLStatement&gt; statementList = SQLUtils.parseStatements(sql, dbType);</span><br></pre></td></tr></table></figure><h4 id="3-2-通过SQLUtils产生SQLExpr"><a href="#3-2-通过SQLUtils产生SQLExpr" class="headerlink" title="3.2. 通过SQLUtils产生SQLExpr"></a>3.2. 通过SQLUtils产生SQLExpr</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">String dbType = JdbcConstants.MYSQL;</span><br><span class="line">SQLExpr expr = SQLUtils.toSQLExpr(<span class="string">"id=3"</span>, dbType);</span><br></pre></td></tr></table></figure><h3 id="4-怎样打印AST节点"><a href="#4-怎样打印AST节点" class="headerlink" title="4. 怎样打印AST节点"></a>4. 怎样打印AST节点</h3><h4 id="4-1-通过SQLUtils工具类打印节点"><a href="#4-1-通过SQLUtils工具类打印节点" class="headerlink" title="4.1. 通过SQLUtils工具类打印节点"></a>4.1. 通过SQLUtils工具类打印节点</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> com.alibaba.druid.sql;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SQLUtils</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 可以将SQLExpr/SQLStatement打印为String类型</span></span><br><span class="line">    <span class="function"><span class="keyword">static</span> String <span class="title">toSQLString</span><span class="params">(SQLObject sqlObj, String dbType)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 可以将一个&amp;lt;SQLStatement&amp;gt;打印为String类型</span></span><br><span class="line">    <span class="function"><span class="keyword">static</span> String <span class="title">toSQLString</span><span class="params">(List&lt;SQLStatement&gt; statementList, String dbType)</span></span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="5-如何自定义遍历AST节点"><a href="#5-如何自定义遍历AST节点" class="headerlink" title="5. 如何自定义遍历AST节点"></a>5. 如何自定义遍历AST节点</h3><p>所有的AST节点都支持Visitor模式，需要自定义遍历逻辑，可以实现相应的ASTVisitorAdapter派生类，比如 <a href="https://github.com/alibaba/druid/wiki/SQL_Parser_Demo_visitor" target="_blank" rel="noopener">https://github.com/alibaba/druid/wiki/SQL_Parser_Demo_visitor</a></p><h3 id="6-相关阅读"><a href="#6-相关阅读" class="headerlink" title="6. 相关阅读"></a>6. 相关阅读</h3><ul><li><a href="https://github.com/alibaba/druid/wiki/SQL-Parser" target="_blank" rel="noopener">https://github.com/alibaba/druid/wiki/SQL-Parser</a></li><li><a href="https://github.com/alibaba/druid/wiki/SQL_Schema_Repository" target="_blank" rel="noopener">https://github.com/alibaba/druid/wiki/SQL_Schema_Repository</a></li><li><a href="https://github.com/alibaba/druid/wiki/SQL_RemoveCondition_demo" target="_blank" rel="noopener">https://github.com/alibaba/druid/wiki/SQL_RemoveCondition_demo</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> SQL </tag>
            
            <tag> Druid </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Zookeeper 入门</title>
      <link href="/posts/a097aeed/"/>
      <url>/posts/a097aeed/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在使用kafka，Hbase等大数据组件时，发现很多开源项目都用到了Zookeeper。所以在这里简单研究一下Zookeeper</p><h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><h2 id="Zookeeper-是什么"><a href="#Zookeeper-是什么" class="headerlink" title="Zookeeper 是什么"></a>Zookeeper 是什么</h2><p>Zookeeper是一个分布式协调框架，实现同步服务，配置维护和命名服务等分布式应用。是一个高性能的分布式数据一致性解决方案</p><h2 id="Zookeeper-能干什么"><a href="#Zookeeper-能干什么" class="headerlink" title="Zookeeper 能干什么"></a>Zookeeper 能干什么</h2><p>可以在分布式系统中共享配置，协调锁资源，提供命名服务</p><ol><li>分布式锁：利用Zookeeper的临时顺序节点，可以轻松实现分布式锁</li><li>服务注册与发现： 利用Znode和Watcher，可以实现分布式服务的注册与发现。如：Dubbo</li><li>共享配置与状态信息：如Redis的分布式Codis，利用Zookeeper存放数据路由表和codis-proxy节点的元信息，同时codis-config发起的命令都会通过Zookeeper同步到各个存活的codis-proxy。</li></ol><h3 id="Zookeeper-的数据模型"><a href="#Zookeeper-的数据模型" class="headerlink" title="Zookeeper 的数据模型"></a>Zookeeper 的数据模型</h3><p>Zookeeper的数据模型类似于数据结构中的树，也类似于Linux文件系统中的目录</p><p>树由多个节点构成，Zookeeper的数据存储同样基于节点。在 Zookeeper 中，这样的节点被称作为 Znode</p><p>Zookeeper的引用方式是路径引用，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">/tree1/node1</span><br><span class="line">/tree2/node2</span><br></pre></td></tr></table></figure><p>这种层级结构可以让每一个Znode节点拥有唯一的路径，可以对不同信息做出清晰的隔离</p><h3 id="Znode-里有什么？"><a href="#Znode-里有什么？" class="headerlink" title="Znode 里有什么？"></a>Znode 里有什么？</h3><p>Znode包含了数据，子节点引用，访问权限等数据。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">|         data           |  ACL  |</span><br><span class="line">---------------------------------</span><br><span class="line">|child (znode1,znode2...)|  stat |</span><br><span class="line"></span><br><span class="line">data 负责存储Znode存储的数据信息</span><br><span class="line">ACL  记录Znode的访问权限，谁可以访问本节点</span><br><span class="line">stat 包含Znode的各种元数据，如：事务ID、版本号、时间戳、大小 等</span><br><span class="line">child当前节点的子节点引用，类似于二叉树的左右孩子</span><br></pre></td></tr></table></figure><p>需要注意的是Zookeeper是为了读多写少的场景所设计，Znode并非是用来存储大规模业务数据，而是用于存储少量的状态与配置信息，每个节点的数据最大不能超过 1MB！</p><h2 id="Zookeeper-运行原理是什么"><a href="#Zookeeper-运行原理是什么" class="headerlink" title="Zookeeper 运行原理是什么"></a>Zookeeper 运行原理是什么</h2><h3 id="什么是Watch？"><a href="#什么是Watch？" class="headerlink" title="什么是Watch？"></a>什么是Watch？</h3><p>可以理解为注册在特定Znode上的触发器，当这个Znode发生改变，也就是调用了create,delete,setData方法的时候，将会触发Znode上注册的对应事件，请求Watch的客户端将会收到异步通知</p><h4 id="Watch的交互过程"><a href="#Watch的交互过程" class="headerlink" title="Watch的交互过程"></a>Watch的交互过程</h4><p>这里借用程序猿小灰博文中的图：</p><ol><li>客户端调用getData方法，watch参数为 true 。服务端收到请求，返回节点数据，并且在对应的哈希表中插入被Watch的Znode路径。以及Watcher列表。</li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200804235728.jpeg" alt=""></p><ol start="2"><li>当被watch的Znode已删除，服务端会查找哈希表，找到该Znode对应的所有Watcher，异步通知客户端，并且删除hash表中对应的 K-V</li></ol><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200804235659.jpeg" alt=""></p><h3 id="Zookeeper-的一致性"><a href="#Zookeeper-的一致性" class="headerlink" title="Zookeeper 的一致性"></a>Zookeeper 的一致性</h3><p>如果Zookeeper自身挂掉了，它作为分布式的协调服务，应该怎么办？</p><p>为了防止Zookeeper单机挂掉的情况，Zookeeper维护了一个集群</p><p>这里还是借用小灰的图：</p><p><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200804235334.png" alt=""></p><p>Zookeeper服务的集群是一主多从的结构。</p><p>在更新数据时，首先更新到主节点（服务器，非Znode），再同步到从节点。</p><p>在读取数据时，直接读取任意从节点</p><p>为了保证主从节点的数据一致性，Zookeeper采用了自己的ZAB协议。类似于一致性算法Paxos与Raft</p><p>ZAB协议是：Zookeeper Atomic Broadcast。 有效解决Zookeeper的集群崩溃恢复，以及主从同步数据的问题。</p><h4 id="ZAB协议"><a href="#ZAB协议" class="headerlink" title="ZAB协议"></a>ZAB协议</h4><p>ZAB协议定义了三种节点状态</p><ul><li>Looking：选举状态</li><li>Following：从节点所处的状态</li><li>Leading： Leader节点所处的状态</li></ul><h4 id="最大ZXID"><a href="#最大ZXID" class="headerlink" title="最大ZXID"></a>最大ZXID</h4><p>最大ZXID也就是节点本地的最新事务编号，包含epoch与计数两部分。epoch是纪元的意思，相当于Raft算法选主时候的term</p><h4 id="Zookeeper集群崩溃恢复"><a href="#Zookeeper集群崩溃恢复" class="headerlink" title="Zookeeper集群崩溃恢复"></a>Zookeeper集群崩溃恢复</h4><p>假如Zookeeper当前主节点挂掉了，集群会进行崩溃恢复。ZAB的崩溃恢复分为三个阶段：</p><ol><li>Leader election</li></ol><p>选举阶段，此时集群中的节点处于Looking状态。他们会各自向其他节点发起投票，投票当中包含自己的服务器ID和最新事务ID（ZXID）</p><p>接下来，节点会用自身的ZXID和从其他节点接受到的ZXID做比较，如果发现其他结点的ZXID比自己大，也就是数据比自己新，那么就重新发起投票，投票给目前已知最大的ZXID所属节点</p><p>每次投票后，服务器会统计投票数量，判断是否有某个节点获得半数以上的投票。如果存在这样的节点，该节点将会成为准Leader，状态变为Leading。其他节点随之变为Following。</p><ol start="2"><li>Discovery</li></ol><p>发现阶段，用于在从节点中发现最新的ZXID与事务日志。这是为了防止因为某些意外情况，比如网络原因在上一阶段产生多个Leader的情况。</p><p>所以在此阶段，Leader接收所有Follower发来各自的最新epoch值。Leader从中选出最大的epoch，基于此值+1，生成新的epoch分发给各个Follower</p><p>各个Follow二收到全新的epoch后，返回ACK给Leader，带上各自最大的ZXID和历史事务日志。Leader选出最大的ZXID，并更新自身历史日志。</p><ol start="3"><li>Synchronization</li></ol><p>同步阶段，把Leader刚才收集到的最新历史事务日志，同步给集群中所有的Follower。只有当半数Follower同步成功，这个准Leader才能成为正式Leader</p><p>故障恢复结束</p><h4 id="ZAB如何写入数据？"><a href="#ZAB如何写入数据？" class="headerlink" title="ZAB如何写入数据？"></a>ZAB如何写入数据？</h4><p>在写入过程中，涉及到ZAB协议的Broadcast阶段</p><p>Broadcast是Zookeeper常规情况下更新数据的时候，由Leader广播到所有的Follower。其过程如下：</p><ol><li><p>客户端发出写入数据请求给任意Follower</p></li><li><p>Follower把写入数据请求转发给Leader</p></li><li><p>Leader采用二阶段提交方式，先发送Propose广播给Follower。</p></li><li><p>Follower接到Propose消息，写入日志成功后，返回ACK消息给leader</p></li><li><p>leader接到半数以上ACK消息，返回成功给客户端，并且广播Commit请求给Follower</p></li></ol><p>ZAB协议并非强一致性，也不是弱一致性，而是处于两者之间的单调一致性。它依靠事务ID和版本号，保证了数据的更新和读取是有序的。</p><h2 id="Zookeeper-怎么使用"><a href="#Zookeeper-怎么使用" class="headerlink" title="Zookeeper 怎么使用"></a>Zookeeper 怎么使用</h2><p>Zookeeper 为开发者们提供了一些简单的API，甚至提供了触发器机制。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">create 创建节点</span><br><span class="line">delete 删除节点</span><br><span class="line">exist  判断节点是否存在（读操作）</span><br><span class="line">getData 获得一个节点的数据（读操作）</span><br><span class="line">setData 设置一个节点的数据</span><br><span class="line">getChildren 获取节点下的所有子节点（读操作）</span><br></pre></td></tr></table></figure><p>Zookeeper客户端在请求读操作的时候，可以选择是否设置Watch</p><h3 id="搭建"><a href="#搭建" class="headerlink" title="搭建"></a>搭建</h3><p>从官方网站下载zookeeper的最新安装包：<a href="https://zookeeper.apache.org/releases.html" target="_blank" rel="noopener">链接</a></p><h4 id="单机版"><a href="#单机版" class="headerlink" title="单机版"></a>单机版</h4><p>单机版很简单，直接解压zookeeper的压缩包，进入conf目录下，复制一份zoo_sample.cfg文件到conf目录下命名为zoo.cfg,根据自己的需要修改配置即可</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The number of milliseconds of each tick</span></span><br><span class="line"><span class="attr">tickTime</span>=<span class="string">2000</span></span><br><span class="line"><span class="comment"># The number of ticks that the initial </span></span><br><span class="line"><span class="comment"># synchronization phase can take</span></span><br><span class="line"><span class="attr">initLimit</span>=<span class="string">10</span></span><br><span class="line"><span class="comment"># The number of ticks that can pass between </span></span><br><span class="line"><span class="comment"># sending a request and getting an acknowledgement</span></span><br><span class="line"><span class="attr">syncLimit</span>=<span class="string">5</span></span><br><span class="line"><span class="comment"># the directory where the snapshot is stored.</span></span><br><span class="line"><span class="comment"># do not use /tmp for storage, /tmp here is just </span></span><br><span class="line"><span class="comment"># example sakes.</span></span><br><span class="line"><span class="attr">dataDir</span>=<span class="string">/tmp/zookeeper</span></span><br><span class="line"><span class="comment"># the port at which the clients will connect</span></span><br><span class="line"><span class="attr">clientPort</span>=<span class="string">2181</span></span><br><span class="line"><span class="comment"># the maximum number of client connections.</span></span><br><span class="line"><span class="comment"># increase this if you need to handle more clients</span></span><br><span class="line"><span class="comment">#maxClientCnxns=60</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Be sure to read the maintenance section of the </span></span><br><span class="line"><span class="comment"># administrator guide before turning on autopurge.</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># http://zookeeper.apache.org/doc/current/zookeeperAdmin.html#sc_maintenance</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># The number of snapshots to retain in dataDir</span></span><br><span class="line"><span class="comment">#autopurge.snapRetainCount=3</span></span><br><span class="line"><span class="comment"># Purge task interval in hours</span></span><br><span class="line"><span class="comment"># Set to "0" to disable auto purge feature</span></span><br><span class="line"><span class="comment">#autopurge.purgeInterval=1</span></span><br></pre></td></tr></table></figure><p>然后运行bin目录下的zkServer.sh即可启动</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@bogon bin]# zkServer.sh start</span><br><span class="line">ZooKeeper JMX enabled by default</span><br><span class="line">Using config: /opt/apache-zookeeper-3.5.7-bin/bin/../conf/zoo.cfg</span><br><span class="line">Starting zookeeper ... STARTED</span><br></pre></td></tr></table></figure><h4 id="集群搭建"><a href="#集群搭建" class="headerlink" title="集群搭建"></a>集群搭建</h4><p>集群搭建也很简单，只需要在上述的zoo.cfg文件中加入一下配置</p><figure class="highlight properties"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">server.zk1</span>=<span class="string">xxx.xxx.x.xx:2888:3888</span></span><br><span class="line"><span class="meta">server.zk2</span>=<span class="string">xxx.xxx.x.xx:2888:3888</span></span><br><span class="line"><span class="meta">server.zk3</span>=<span class="string">xxx.xxx.x.xx:2888:3888</span></span><br></pre></td></tr></table></figure><p>其中2888为通信端口号，3888为选举端口号</p><p>然后分别启动三台Zookeeper的服务即可</p>]]></content>
      
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Zookeeper </tag>
            
            <tag> 分布式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Java 网络编程之 SSL加密连接</title>
      <link href="/posts/8662ab0e/"/>
      <url>/posts/8662ab0e/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>关于SSL加密连接方式的一切在这里就不再赘述，这里主要分享关于在Java编程中如何对SSL进行编码</p><h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><h2 id="几个重要的类"><a href="#几个重要的类" class="headerlink" title="几个重要的类"></a>几个重要的类</h2><h3 id="KeyStore"><a href="#KeyStore" class="headerlink" title="KeyStore"></a>KeyStore</h3><p>表示密钥和证书的存储设施</p><p>主要用于存放证书，创建对象时，指定交换数字证书的加密标准</p><p>用法如下(以pkcs12为例)：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">InputStream stream=<span class="keyword">new</span> FileInputStream(<span class="keyword">new</span> Filel(<span class="string">"your file path"</span>));</span><br><span class="line"><span class="keyword">char</span>[] password=<span class="string">"your password"</span>.toCharArray();</span><br><span class="line">KeyStore keyStore=KeyStore.getInstance(<span class="string">"PKCS12"</span>);</span><br><span class="line">keyStore.load(stream, password);</span><br><span class="line">stream.close();</span><br></pre></td></tr></table></figure><h3 id="KeyManager"><a href="#KeyManager" class="headerlink" title="KeyManager"></a>KeyManager</h3><p>选择证书来证明自己的身份</p><p>这是用于 JSSE 密钥管理器的基接口。</p><p>KeyManager 负责管理用于验证到同位体的本地 SSLSocket 的密钥内容。如果没有密钥内容可以使用，则套接字将不能提供验证证书。</p><p>通过使用 KeyManagerFactory，或实现 KeyManager 子类之一来创建 KeyManager。</p><p>用法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这里的 keyStore、password 可以参考上方代码</span></span><br><span class="line">KeyManagerFactory keyManagerFactory=KeyManagerFactory.getInstance(<span class="string">"PKCS12"</span>);</span><br><span class="line">keyManagerFactory.init(keyStore,password);</span><br><span class="line">KeyManager[] keyManagers=keyManagerFactory.getKeyManagers();</span><br></pre></td></tr></table></figure><h3 id="TrustManager"><a href="#TrustManager" class="headerlink" title="TrustManager"></a>TrustManager</h3><p>决定是否信任对方的证书</p><p>这是用于 JSSE 信任管理器的基接口。</p><p>TrustManager 负责管理做出信任决定时使用的的信任材料，也负责决定是否接受同位体提供的证书。</p><p>通过使用 TrustManagerFactory，或实现 TrustManager 子类之一创建 TrustManager。</p><p>用法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 这里的 keyStore 可以参考上方代码</span></span><br><span class="line">TrustManagerFactory trustManagerFactory=TrustManagerFactory.getInstance(<span class="string">"PKCS12"</span>);</span><br><span class="line">trustManagerFactory.init(keyStore);</span><br><span class="line">TrustManager[] trustManagers=trustManagerFactory.getTrustManagers();</span><br></pre></td></tr></table></figure><h3 id="SSLContext"><a href="#SSLContext" class="headerlink" title="SSLContext"></a>SSLContext</h3><p>此类的实例表示安全套接字协议的实现，它充当用于安全套接字工厂或 SSLEngine 的工厂。用可选的一组密钥和信任管理器及安全随机字节源初始化此类。</p><p>用法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SSLContext context=SSLContext.getInstance(<span class="string">"SSL"</span>);</span><br><span class="line">context.init(keyManagers, trustManagers, <span class="keyword">null</span>);</span><br></pre></td></tr></table></figure><h3 id="SSLEngine"><a href="#SSLEngine" class="headerlink" title="SSLEngine"></a>SSLEngine</h3><p>数据发送前wrap打包加密，数据接收时unwrap解包解密，这样一个tcp数据包通过SSLEngine的过程。如下图所示（来自JDK源码）</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">                app data</span><br><span class="line">             |           ^</span><br><span class="line">             |     |     |</span><br><span class="line">             v     |     |</span><br><span class="line">        +----+-----|-----+----+</span><br><span class="line">        |          |          |</span><br><span class="line">        |       SSL|Engine    |</span><br><span class="line">wrap()  |          |          |  unwrap()</span><br><span class="line">        | OUTBOUND | INBOUND  |</span><br><span class="line">        |          |          |</span><br><span class="line">        +----+-----|-----+----+</span><br><span class="line">             |     |     ^</span><br><span class="line">             |     |     |</span><br><span class="line">             v           |</span><br><span class="line">                net data</span><br></pre></td></tr></table></figure><p>用法如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 此context为上文提到的SSLContext</span></span><br><span class="line">SSLEngine engine = context.createSSLEngine();</span><br></pre></td></tr></table></figure><h2 id="证书互相转换"><a href="#证书互相转换" class="headerlink" title="证书互相转换"></a>证书互相转换</h2><h3 id="pem格式证书转为pkcs12格式"><a href="#pem格式证书转为pkcs12格式" class="headerlink" title="pem格式证书转为pkcs12格式"></a>pem格式证书转为pkcs12格式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl pkcs12 -export -in client.pem -out client.p12</span><br></pre></td></tr></table></figure><h3 id="pem格式证书导出x509格式"><a href="#pem格式证书导出x509格式" class="headerlink" title="pem格式证书导出x509格式"></a>pem格式证书导出x509格式</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">openssl x509 -outform der -in client.pem -out client.crt</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Java 编程相关 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> SSL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MongoDB 报文解读</title>
      <link href="/posts/c88df007/"/>
      <url>/posts/c88df007/</url>
      
        <content type="html"><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><script class="meting-secondary-script-marker" src="\assets\js\Meting.min.js"></script><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>由于工作和学习的需要，需要对 MongoDB 的报文进行分析和解读，故通过 Wireshark 进行 MongoDB 的抓包进行分析和学习</p><h1 id="正文"><a href="#正文" class="headerlink" title="正文"></a>正文</h1><p>在抓包过程中，我们发现 MongoDB 在3.6之后引入了新的数据交换格式，与之前不同，但总体报文解析逻辑是相同的</p><p>话不多说，先上MongoDB数据包的正确打开方式</p><h2 id="配置MongoDB协议解码器"><a href="#配置MongoDB协议解码器" class="headerlink" title="配置MongoDB协议解码器"></a>配置MongoDB协议解码器</h2><ol><li><p>配置需要解码的端口号和协议<br><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200402145752.png" alt=""><br><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200402145814.png" alt="配置端口和协议"></p></li><li><p>过滤掉除MongoDB外的其他报文<br><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200402145842.png" alt="配置过滤规则"></p></li><li><p>打开一个已经解码好的报文<br><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200402145858.png" alt="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200402145858.png"><br><img src= "/img/loading.gif" data-lazy-src="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200402145926.png" alt="https://lemongo97-blog-img.oss-cn-beijing.aliyuncs.com/20200402145926.png"></p></li></ol><p>这样，我们就可以很直观的看到数据包中都传递了那些数据</p><p>对于 MongoDB 的协议来说，OpCode是一个很重要的东西，根据OpCode，MongoDB区分了不同版本的报文结构。我们在Wireshark中看到的报文结构，都是经过完全解码后的数据。</p><p>官方文档中也有对协议内容的一个大致说明：<a href="https://docs.mongodb.com/manual/reference/mongodb-wire-protocol/" target="_blank" rel="noopener">官方的协议说明</a></p><p>在报文中有固定的一些字段，如下：</p><table><thead><tr><th align="center">Field</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">messageLength</td><td align="left">The total size of the message in bytes. This total includes the 4 bytes that holds the message length.</td></tr><tr><td align="center">requestID</td><td align="left">A client or database-generated identifier that uniquely identifies this message. For the case of client-generated messages (e.g. OP_QUERY and OP_GET_MORE), it will be returned in the responseTo field of the OP_REPLY message. Clients can use the requestID and the responseTo fields to associate query responses with the originating query.</td></tr><tr><td align="center">responseTo</td><td align="left">In the case of a message from the database, this will be the requestID taken from the OP_QUERY or OP_GET_MORE messages from the client. Clients can use the requestID and the responseTo fields to associate query responses with the originating query.</td></tr><tr><td align="center">opCode</td><td align="left">Type of message. See Request Opcodes for details.</td></tr></tbody></table><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">MsgHeader</span> &#123;</span></span><br><span class="line">    int32   messageLength; <span class="comment">// total message size, including this</span></span><br><span class="line">    int32   requestID;     <span class="comment">// identifier for this message</span></span><br><span class="line">    int32   responseTo;    <span class="comment">// requestID from the original request</span></span><br><span class="line">                           <span class="comment">//   (used in responses from db)</span></span><br><span class="line">    int32   opCode;        <span class="comment">// request type - see table below for details</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>messageLength：代表了MongoDB一次消息通讯中的消息总长度，位置在消息头部。</p><p>requestId：一般为请求发起方的消息包ID，此ID是自增长的，MongoDB会根据这个Id来返回这个ID对应的数据包</p><p>responseTo：一般为MongoDB返回的消息包ID，这个ID为请求包的requestId</p><p>opCode：代表了数据包中的消息类型，具体的OpCode的对应关系如下</p><p>OpCode编号与其含义对应如下：</p><blockquote><p>NOTE:<br>Starting with MongoDB 2.6 and maxWireVersion 3, MongoDB drivers use the database commands insert, update, and delete instead of OP_INSERT, OP_UPDATE, and OP_DELETE for acknowledged writes. Most drivers continue to use opcodes for unacknowledged writes.<br>In version 4.2, MongoDB removes the deprecated internal OP_COMMAND and OP_COMMANDREPLY protocol.</p></blockquote><table><thead><tr><th align="center">Opcode Name</th><th align="center">Value</th><th align="left">Comment</th></tr></thead><tbody><tr><td align="center">OP_REPLY</td><td align="center">1</td><td align="left">Reply to a client request. responseTo is set.</td></tr><tr><td align="center">OP_UPDATE</td><td align="center">2001</td><td align="left">Update document.</td></tr><tr><td align="center">OP_INSERT</td><td align="center">2002</td><td align="left">Insert new document.</td></tr><tr><td align="center">RESERVED</td><td align="center">2003</td><td align="left">Formerly used for OP_GET_BY_OID.</td></tr><tr><td align="center">OP_QUERY</td><td align="center">2004</td><td align="left">Query a collection.</td></tr><tr><td align="center">OP_GET_MORE</td><td align="center">2005</td><td align="left">Get more data from a query. See Cursors.</td></tr><tr><td align="center">OP_DELETE</td><td align="center">2006</td><td align="left">Delete documents.</td></tr><tr><td align="center">OP_KILL_CURSORS</td><td align="center">2007</td><td align="left">Notify database that the client has finished with the cursor.</td></tr><tr><td align="center">OP_MSG</td><td align="center">2013</td><td align="left">Send a message using the format introduced in MongoDB 3.6.</td></tr></tbody></table><h2 id="具体类型的-OP-CODE-格式解析"><a href="#具体类型的-OP-CODE-格式解析" class="headerlink" title="具体类型的 OP_CODE 格式解析"></a>具体类型的 OP_CODE 格式解析</h2><h3 id="OP-INSERT"><a href="#OP-INSERT" class="headerlink" title="OP_INSERT"></a>OP_INSERT</h3><p>OP_INSERT消息用于将一个或多个文档插入到集合中。OP_INSERT消息的格式为</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    MsgHeader header;             <span class="comment">// standard message header</span></span><br><span class="line">    int32     flags;              <span class="comment">// bit vector - see below</span></span><br><span class="line">    cstring   fullCollectionName; <span class="comment">// "dbname.collectionname"</span></span><br><span class="line">    document* documents;          <span class="comment">// one or more documents to insert into the collection</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Field</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">header</td><td align="left">消息头，参照上方标准消息头</td></tr><tr><td align="center">flags</td><td align="left">位向量，用于指定操作标志。如果为0，则数据库不会因为某条数据插入失败而停止插入。1-31为数据库保留</td></tr><tr><td align="center">fullCollectionName</td><td align="left">完整的集合名称，也被称为命名空间，一般格式为: &lt;数据库.集合名&gt;</td></tr><tr><td align="center">documents</td><td align="left">一个或多个要插入集合的文档。如果有多个，则依次将它们依次写入socket。</td></tr></tbody></table><p>OP_INSERT消息无响应。</p><h3 id="OP-DELETE"><a href="#OP-DELETE" class="headerlink" title="OP_DELETE"></a>OP_DELETE</h3><p>OP_DELETE消息用于从集合中删除一个或多个文档。OP_DELETE消息的格式为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    MsgHeader header;             <span class="comment">// standard message header</span></span><br><span class="line">    int32     ZERO;               <span class="comment">// 0 - reserved for future use</span></span><br><span class="line">    cstring   fullCollectionName; <span class="comment">// "dbname.collectionname"</span></span><br><span class="line">    int32     flags;              <span class="comment">// bit vector - see below for details.</span></span><br><span class="line">    document  selector;           <span class="comment">// query object.  See below for details.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Field</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">header</td><td align="left">消息头，参照上方标准消息头</td></tr><tr><td align="center">ZERO</td><td align="left">整数值0。暂未使用，官方称保留以备将来使用</td></tr><tr><td align="center">numberOfCursorIDs</td><td align="left">消息中的游标ID的数量</td></tr><tr><td align="center">cursorIDs</td><td align="left">要删除的游标ID的“数组”。如果有多个，则依次将它们依次写入套接字</td></tr></tbody></table><p>如果游标被读取直到用尽（直到OP_QUERY 或OP_GET_MORE返回零作为游标ID），就没有必要终止游标</p><h3 id="OP-UPDATE"><a href="#OP-UPDATE" class="headerlink" title="OP_UPDATE"></a>OP_UPDATE</h3><p>OP_UPDATE消息用于更新集合中的文档。OP_UPDATE消息的格式如下：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">OP_UPDATE</span> &#123;</span></span><br><span class="line">    MsgHeader header;             <span class="comment">// standard message header</span></span><br><span class="line">    int32     ZERO;               <span class="comment">// 0 - reserved for future use</span></span><br><span class="line">    cstring   fullCollectionName; <span class="comment">// "dbname.collectionname"</span></span><br><span class="line">    int32     flags;              <span class="comment">// bit vector. see below</span></span><br><span class="line">    document  selector;           <span class="comment">// the query to select the document</span></span><br><span class="line">    document  update;             <span class="comment">// specification of the update to perform</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Field</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">header</td><td align="left">消息头，参照上方标准消息头</td></tr><tr><td align="center">ZERO</td><td align="left">整数值0。暂未使用，官方称保留以备将来使用</td></tr><tr><td align="center">fullCollectionName</td><td align="left">完整的集合名称，也被称为命名空间，一般格式为: &lt;数据库.集合名&gt;</td></tr><tr><td align="center">flags</td><td align="left">位向量，用于指定操作标志。0：对应于Upsert。如果设置，则如果找不到匹配的文档，数据库将把提供的对象插入集合中。1：对应于MultiUpdate。如果设置，数据库将更新集合中的所有匹配对象。否则，仅更新第一个匹配的文档。2- 31保留。必须设置为0。</td></tr><tr><td align="center">selector</td><td align="left">BSON文档，指定用于选择要更新的文档的查询。</td></tr><tr><td align="center">update</td><td align="left">BSON文档，指定要执行的更新</td></tr></tbody></table><p>OP_UPDATE消息无响应。</p><h3 id="OP-QUERY"><a href="#OP-QUERY" class="headerlink" title="OP_QUERY"></a>OP_QUERY</h3><p>OP_QUERY消息用于在数据库中查询集合中的文档。OP_QUERY消息的格式为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">OP_QUERY</span> &#123;</span></span><br><span class="line">    MsgHeader header;                 <span class="comment">// standard message header</span></span><br><span class="line">    int32     flags;                  <span class="comment">// bit vector of query options.  See below for details.</span></span><br><span class="line">    cstring   fullCollectionName ;    <span class="comment">// "dbname.collectionname"</span></span><br><span class="line">    int32     numberToSkip;           <span class="comment">// number of documents to skip</span></span><br><span class="line">    int32     numberToReturn;         <span class="comment">// number of documents to return</span></span><br><span class="line">                                      <span class="comment">//  in the first OP_REPLY batch</span></span><br><span class="line">    document  query;                  <span class="comment">// query object.  See below for details.</span></span><br><span class="line">  [ document  returnFieldsSelector; ] <span class="comment">// Optional. Selector indicating the fields</span></span><br><span class="line">                                      <span class="comment">//  to return.  See below for details.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Field</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">header</td><td align="left">消息头，参照上方标准消息头</td></tr><tr><td align="center">flags</td><td align="left">位向量，用于指定操作标志。</td></tr><tr><td align="center">fullCollectionName</td><td align="left">完整的集合名称，也被称为命名空间，一般格式为: &lt;数据库.集合名&gt;</td></tr><tr><td align="center">numberToSkip</td><td align="left">设置要跳过的文档数-从结果数据集中的第一个文档开始-返回查询结果时。</td></tr><tr><td align="center">numberToReturn</td><td align="left">将第一个OP_REPLY消息中的文档数限制为查询。但是，cursorID如果结果多于，数据库仍将建立游标并将其返回给客户端numberToReturn。如果客户端驱动程序提供了“限制”功能（例如SQL LIMIT关键字），则由客户端驱动程序来确保将不超过指定数量的文档返回给调用应用程序。如果numberToReturn为0，则数据库将使用默认的返回大小。如果数字为负，则数据库将返回该数字并关闭游标。无法获取该查询的其他结果。如果numberToReturn为， 1则服务器会将其视为-1（自动关闭光标）。</td></tr><tr><td align="center">query</td><td align="left">代表查询的BSON文档。该查询将包含一个或多个元素，所有这些元素都必须匹配才能使文档包含在结果集中。可能的因素包括 $query，$orderby，$hint，和$explain。</td></tr><tr><td align="center">returnFieldsSelector</td><td align="left">可选BSON文档，用于限制返回文档中的字段。所述returnFieldsSelector含有一种或多种元素，其中的每一个是应返回字段的名称，以及整数值1。</td></tr></tbody></table><p>对于上方flags字段，具体描述如下：</p><ul><li>0被预定了。必须设置为0。</li><li>1对应于TailableCursor。可拖尾表示检索到最后一个数据时光标未关闭。而是，光标标记最终对象的位置。如果收到更多数据，则可以稍后从光标所在的位置继续使用它。像任何“潜在游标”一样，游标可能会在某个时候失效（CursorNotFound）–例如，如果删除了它所引用的最终对象。</li><li>2对应于SlaveOk.Allow查询副本从属。通常，这些返回错误，但名称空间“ local”除外。</li><li>3对应于OplogReplay。仅供内部复制使用-不应设置驱动程序。</li><li>4对应于NoCursorTimeout。服务器通常在闲置时间（10分钟）后使空闲游标超时，以防止过多使用内存。设置此选项可以防止这种情况。</li><li>5对应于AwaitData。与TailableCursor一起使用。如果我们在数据的末尾，请阻塞一会儿，而不要返回任何数据。超时后，我们照常返回。</li><li>6对应于排气。假设客户端将完全读取所有查询的数据，则将数据以多个“更多”包的形式完整传输。当您提取大量数据并知道要全部提取时，速度更快。注意：除非客户端关闭连接，否则不允许客户端不读取所有数据。</li><li>7对应于部分。如果某些分片发生故障，则从mongos获得部分结果（而不是引发错误）</li><li>8-31保留。必须设置为0。</li></ul><p>数据库使用OP_REPLY消息来响应 OP_QUERY消息。</p><h3 id="OP-GET-MORE"><a href="#OP-GET-MORE" class="headerlink" title="OP_GET_MORE"></a>OP_GET_MORE</h3><p>OP_GET_MORE消息用于在数据库中查询集合中的文档。OP_GET_MORE消息的格式为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    MsgHeader header;             <span class="comment">// standard message header</span></span><br><span class="line">    int32     ZERO;               <span class="comment">// 0 - reserved for future use</span></span><br><span class="line">    cstring   fullCollectionName; <span class="comment">// "dbname.collectionname"</span></span><br><span class="line">    int32     numberToReturn;     <span class="comment">// number of documents to return</span></span><br><span class="line">    int64     cursorID;           <span class="comment">// cursorID from the OP_REPLY</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Field</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">header</td><td align="left">消息头，参照上方标准消息头</td></tr><tr><td align="center">ZERO</td><td align="left">整数值0。暂未使用，官方称保留以备将来使用</td></tr><tr><td align="center">fullCollectionName</td><td align="left">完整的集合名称，也被称为命名空间，一般格式为: &lt;数据库.集合名&gt;</td></tr><tr><td align="center">numberToReturn</td><td align="left">将第一个OP_REPLY消息中的文档数限制为查询。但是，cursorID如果结果多于，数据库仍将建立游标并将其返回给客户端numberToReturn。如果客户端驱动程序提供了“限制”功能（例如SQL LIMIT关键字），则由客户端驱动程序来确保将不超过指定数量的文档返回给调用应用程序。如果numberToReturn为0，则数据库将使用默认的返回大小。</td></tr><tr><td align="center">cursorID</td><td align="left">OP_REPLY中的光标标识符。这必须是来自数据库的值。</td></tr></tbody></table><p>数据库将以OP_REPLY消息响应 OP_GET_MORE消息。</p><h3 id="OP-KILL-CURSORS"><a href="#OP-KILL-CURSORS" class="headerlink" title="OP_KILL_CURSORS"></a>OP_KILL_CURSORS</h3><p>OP_KILL_CURSORS消息用于关闭数据库中的活动游标。这是确保查询结束时回收数据库资源所必需的。OP_KILL_CURSORS消息的格式为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    MsgHeader header;            <span class="comment">// standard message header</span></span><br><span class="line">    int32     ZERO;              <span class="comment">// 0 - reserved for future use</span></span><br><span class="line">    int32     numberOfCursorIDs; <span class="comment">// number of cursorIDs in message</span></span><br><span class="line">    int64*    cursorIDs;         <span class="comment">// sequence of cursorIDs to close</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Field</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">header</td><td align="left">消息头，参照上方标准消息头</td></tr><tr><td align="center">ZERO</td><td align="left">整数值0。暂未使用，官方称保留以备将来使用</td></tr><tr><td align="center">numberOfCursorIDs</td><td align="left">消息中的游标ID的数量。</td></tr><tr><td align="center">cursorIDs</td><td align="left">要关闭的游标ID的“数组”。如果有多个，则依次将它们依次写入socket。</td></tr><tr><td align="center">如果游标被读取直到用尽（直到OP_QUERY 或OP_GET_MORE返回零作为游标ID），就没有必要终止游标。</td><td align="left"></td></tr></tbody></table><h3 id="OP-MSG"><a href="#OP-MSG" class="headerlink" title="OP_MSG"></a>OP_MSG</h3><blockquote><p>MongoDB版本中的新功能： 3.6</p></blockquote><p>OP_MSG是一种可扩展的消息格式，旨在包含其他操作码的功能。OP_MSG消息的格式为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">OP_MSG &#123;</span><br><span class="line">    MsgHeader header;          <span class="comment">// standard message header</span></span><br><span class="line">    uint32 flagBits;           <span class="comment">// message flags</span></span><br><span class="line">    Sections[] sections;       <span class="comment">// data sections</span></span><br><span class="line">    optional&lt;uint32&gt; checksum; <span class="comment">// optional CRC-32C checksum</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Field</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">header</td><td align="left">消息头，参照上方标准消息头</td></tr><tr><td align="center">flagBits</td><td align="left">包含消息标志的整数位掩码</td></tr><tr><td align="center">sections</td><td align="left">消息主体部中，如所描述的章节</td></tr><tr><td align="center">checksum</td><td align="left">可选的CRC-32C校验和，如 Checksum中所述</td></tr></tbody></table><p>具体信息参照下方描述：</p><h4 id="flagBits"><a href="#flagBits" class="headerlink" title="flagBits"></a>flagBits</h4><p>该flagBits整数是编码修改的格式和行为的标志位掩码OP_MSG。</p><p>前16位（0-15）是必需的， 如果设置了一个位置的bit，则解析器务必出错。</p><p>最后16位（16-31）是可选的，解析器务必忽略任何未知的被设置的bit。代理和其他消息转发器必须在转发消息之前清除所有未知的可选位。</p><table><thead><tr><th align="center">Bit</th><th align="center">Name</th><th align="center">Request</th><th align="center">Response</th><th align="left">Description</th></tr></thead><tbody><tr><td align="center">0</td><td align="center">checksumPresent</td><td align="center">✓</td><td align="center">✓</td><td align="left">该消息以4个字节结尾，其中包含CRC-32C [1] 校验和。</td></tr><tr><td align="center">1</td><td align="center">moreToCome</td><td align="center">✓</td><td align="center">✓</td><td align="left">另一条消息将跟随此消息，而无需接收者采取进一步措施。接收器必须不发送另一消息，直到接收到一个具有moreToCome设置为0作为发送可能阻塞，引起死锁。moreToCome 设置了该位的请求将不会收到答复。答复将仅在设置了该exhaustAllowed位的情况下响应此请求。</td></tr><tr><td align="center">16</td><td align="center">exhaustAllowed</td><td align="center">✓</td><td align="center">-</td><td align="left">客户端已准备好使用该moreToCome位对该请求进行多次答复。moreToCome除非请求设置了该位，否则服务器将永远不会产生设置了位的回复。这样可以确保仅在请求者的网络层已准备好多个答复时才发送它们。</td></tr></tbody></table><p>MongoDB 3.6会忽略此标志，并将以一条消息进行响应</p><h4 id="Sections"><a href="#Sections" class="headerlink" title="Sections"></a>Sections</h4><p>一条OP_MSG消息包含一个或多个部分。每个部分都以一个kind指示其类型的字节开头。kind 字节之后的所有内容均构成该节的有效负载。</p><p>可用的部分如下：</p><ul><li>Kind 0: Body</li></ul><p>正文部分被编码为单个 BSON对象。BSON对象中的大小也用作部分的大小。此部分类型是标准命令请求和答复正文。</p><p>所有顶级字段都必须具有唯一的名称。</p><ul><li>Kind 1: Document Sequence</li></ul><table><thead><tr><th align="center">Type</th><th>Description</th></tr></thead><tbody><tr><td align="center">int32</td><td>section的大小.</td></tr><tr><td align="center">C String</td><td>文档序列标识符。在所有当前命令中，此字段是从body section替换的（可能是嵌套的）字段。但是不得也存在于主体部分。</td></tr><tr><td align="center">Zero or more BSON objects</td><td>零个或多个BSON对象。对象不使用分隔符来背对背排序。</td></tr></tbody></table><p>对于Zero or more BSON objects来说，每个对象仅限于maxBSONObjectSize服务器的。所有对象的组合不限于 maxBSONObjSize。<br>一旦size消耗完字节，文档序列就结束。<br>转换为语言级对象时，解析器可以选择将这些对象作为数组合并到序列标识符指定的路径处的数组中。</p><h4 id="Checksum"><a href="#Checksum" class="headerlink" title="Checksum"></a>Checksum</h4><p>每条消息可以以CRC-32C [1]校验和结尾，该校验和覆盖消息中所有字节，校验和本身除外</p><p>从MongoDB 4.2开始：</p><ul><li>mongod如果不使用TLS / SSL连接mongos，则实例，实例和 mongo外壳程序实例将与校验和交换消息。</li><li>mongod如果使用TLS / SSL连接mongos，则实例，实例和 mongo外壳程序实例将跳过校验和。</li></ul><p>如果驱动程序和较旧的二进制文件带有带有校验和的消息，则它们将忽略校验和。</p><p>checksumPresent标志位指示存在校验和。</p><h3 id="OP-REPLY"><a href="#OP-REPLY" class="headerlink" title="OP_REPLY"></a>OP_REPLY</h3><p>该OP_REPLY消息由数据库发送，以响应 OP_QUERY或OP_GET_MORE消息。OP_REPLY消息的格式为：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">    MsgHeader header;         <span class="comment">// standard message header</span></span><br><span class="line">    int32     responseFlags;  <span class="comment">// bit vector - see details below</span></span><br><span class="line">    int64     cursorID;       <span class="comment">// cursor id if client needs to do get more's</span></span><br><span class="line">    int32     startingFrom;   <span class="comment">// where in the cursor this reply is starting</span></span><br><span class="line">    int32     numberReturned; <span class="comment">// number of documents in the reply</span></span><br><span class="line">    document* documents;      <span class="comment">// documents</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><table><thead><tr><th align="center">Field</th><th>Description</th></tr></thead><tbody><tr><td align="center">header</td><td>消息头，参照上方标准消息头</td></tr><tr><td align="center">responseFlags</td><td>指定标志的bit向量</td></tr><tr><td align="center">cursorID</td><td>该cursorID 为 OP_REPLY的一部分。如果查询的结果集适合一个OP_REPLY消息， cursorID则将为0。cursorID必须在用于获取更多数据的任何 OP_GET_MORE消息中使用此值，并且当不再需要通过OP_KILL_CURSORS 消息将其关闭时，客户端也必须将其关闭。</td></tr><tr><td align="center">startingFrom</td><td>游标开始位置</td></tr><tr><td align="center">numberReturned</td><td>返回的文档数量.</td></tr><tr><td align="center">documents</td><td>返回的文档</td></tr></tbody></table><p>对于responseFlags的说明</p><ul><li>0对应于CursorNotFound。在getMore调用时设置，但光标ID在服务器上无效。返回结果为零。</li><li>1对应于QueryFailure。查询失败时设置。结果由一个文档组成，其中包含描述失败的“ $ err”字段。</li><li>2对应于ShardConfigStale。驱动应忽略这一点。只有mongos将看到此设置，在这种情况下，它需要从服务器更新配置。</li><li>3对应于AwaitCapable。当服务器支持AwaitData查询选项时设置。如果不是这样，则客户端应该在Tailable游标的getMore之间睡一会儿。Mongod 1.6版支持AwaitData，因此始终设置AwaitCapable。</li><li>4-31保留。忽视。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 数据库相关 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MongoDB </tag>
            
            <tag> TCP </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
